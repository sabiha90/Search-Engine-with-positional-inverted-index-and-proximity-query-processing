{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "def read_file(file_name): \n",
    "    f = open(file_name,\"r\")\n",
    "    docs = f.readlines()\n",
    "    return docs\n",
    "docs = read_file(\"documents.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving each document text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\', \\'This one was one of the most powerful systems on 2013, and still has some things like Slimport that do a plus when is compared to more modern but lower profile options from now-days.\\', \\'\\', \\'The screen is awesome, the only counter-back is that ridiculously even if is know has the Asus Nexus \"from Google\", Google does the worst use of their own OS, when we compared with the ones on LG or Sony systems.\\', \\'\\', \\'So the Hardware from Asus = 5 Stars, flawless a topnotch gear at great price, this still rocks even on 2015 and next year too.\\', \\'Software, OS from Google= 1 Star, awful even if is updated.\\', \\'',\n",
       " '\\', \"I really love my Nexus! My husband surprised me for my birthday a year ago with this. I\\'d only used an iPhone before so I wasn\\'t sure about getting used to an android operating system but now I prefer it. I love having a back button! I love being able to move the cursor where I want it. I like the size of this, not too big or small. I read a lot of ebooks and its weight is good. I immediately put a tech armor screen protector and devicewear case on it to protect it. Sometimes my camera won\\'t work but if I restart the device than it works again fine. I have an iPhone and iPod touch but I much prefer this to an iPad. The price was great for all the storage and a tablet that is fast and works well.\", \\'',\n",
       " '\\', \"It worked great for the first few months. Then started having issues with the touch screen. Then the charging port went bad and I had to send it to ASUS for repair. The charging problem was fixed but the touch screen issues were not. It seems to be temperature sensitive-in cooler environments it functions properly but when it\\'s warmer the touch screen won\\'t work at all. Also, the charging port that got replaced is going bad again. This tablet would get five stars if it actually worked properly.\", \\'',\n",
       " '\\', \"I\\'ve been using net books for a few years now, finally bought s tablet. I\\'ve had it for over 6mos now and now problems whatsoever. I use it for watching movies, games (emulators), shopping, browsing the web, and I just started editing my gopro videos on it with Kinemaster\", \\'\\', \"I am very surprised at the ease of editing 720p videos from my hero4. I know it\\'s not as good as my big PC or a dedicated video editing machine, but the convenience of this little tablet is what counts. I\\'m just happy to get my videos off my hero4 and onto Vimeo.\", \\'',\n",
       " '\\', \"My pre-teen son bought this with his saved money instead of a laptop. He has used it quite a lot. It is a good device. Responsive, good battery life, tough (he\\'s dropped it several times), etc. Would recommend.\", \\'',\n",
       " '\\', \"Upgraded from a Nexus 7 older model. You can easily notice the difference: The screen is great, the stero speakers and the rear camera additions are really appreciated and overall it feels fast and responsive, unlike my older Nexus 7 (specially after upgrading to Android L). I guess the only thing I\\'m not thrilled about is the responsiveness of the screen, I have the feeling that my older tablet reacted to a lighter touch compared to this one. Overall I\\'m quite happy with my purchase.\", \\'',\n",
       " \"', 'Too Google controlled.', 'Unable to delete things you do not want to use or at least put them on hold.', 'Google should allow elective suspension.', '\",\n",
       " '\\', \"Bricked by an update pushed over the air. This was 100% stock. I loved it for the first year, then this happened 2 months out of warranty. Asus wanted $200 to fix it (more than a new one). Google the problem and you will see it is a widespread issue experienced by hundreds. Asus won\\'t acknowledge the issue. I ended up sending it in just to get the repair estimate and submitted that to American Express which automatically added a year to the warranty when I bought it. I then used the claim money to buy parts on eBay and got it working again. One month later it failed for another common issue. The touch screen became jumpy and unresponsive. Piece of junk I\\'ve wasted too much time on. A shame because I really liked it at first. My dealings with ASUS resulted in a complete loss of confidence with the company. Although some of their products have good reviews (even this one, amazingly), I now avoid ASUS products completely because I\\'m not willing to roll the dice with them again. If ASUS had acknowledged the problem, fixed defective units, and released a revision, it would have cost them a trivial amount of money. It would have been the right thing to do. Instead, they are writing off customers as a less expensive loss.\", \\'',\n",
       " '\\', \"do NOT fall for this crappy super slow tablet.. I tried hard , very hard for two weeks to CONVINCE myself that I\\'m too picky , that I\\'m asking too much ... I tried to justify its flaws .. In vein .. I ended up hating that piece of disaster so much, to the point I HAD TO THROW IT IN THE GARBAGE CAN.. instead of returning it.. I thought to give it as a present to a child but soon I realized that no child deserves to get so frustrated by its slugginess and hardware ugliness\", \\'',\n",
       " '\\', \"This is a great tablet and does everything I could want it to. I use it mainly as an e-reader, but it\\'s nice to have internet and games on the same device.\", \\'']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def text_compile(array):\n",
    "    \n",
    "    normalized_text = []\n",
    "    #this step extracts only the text that is between <DOC> and </DOC>\n",
    "    lines = re.compile('<DOC \\d+>' \"(.*?)\" '</DOC>', re.DOTALL |  re.IGNORECASE ).findall(str(array))\n",
    "    for i in lines:\n",
    "        i = i.replace(\"\\\\n\",\"\") #removing the newline characters from the doc\n",
    "        normalized_text.append(i) #Compiling all the steps in an array\n",
    "    return normalized_text\n",
    "\n",
    "text_compiled = text_compile(docs)\n",
    "text_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the documents in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 'This one was one of the most powerful systems on 2013, and still has some things like Slimport that do a plus when is compared to more modern but lower profile options from now-days.\\', \\'\\', \\'The screen is awesome, the only counter-back is that ridiculously even if is know has the Asus Nexus \"from Google\", Google does the worst use of their own OS, when we compared with the ones on LG or Sony systems.\\', \\'\\', \\'So the Hardware from Asus = 5 Stars, flawless a topnotch gear at great price, this still rocks even on 2015 and next year too.\\', \\'Software, OS from Google= 1 Star, awful even if is updated.\\', \\'',\n",
       " 'doc10': 'This is a great tablet and does everything I could want it to. I use it mainly as an e-reader, but it\\'s nice to have internet and games on the same device.\", \\'',\n",
       " 'doc2': 'I really love my Nexus! My husband surprised me for my birthday a year ago with this. I\\'d only used an iPhone before so I wasn\\'t sure about getting used to an android operating system but now I prefer it. I love having a back button! I love being able to move the cursor where I want it. I like the size of this, not too big or small. I read a lot of ebooks and its weight is good. I immediately put a tech armor screen protector and devicewear case on it to protect it. Sometimes my camera won\\'t work but if I restart the device than it works again fine. I have an iPhone and iPod touch but I much prefer this to an iPad. The price was great for all the storage and a tablet that is fast and works well.\", \\'',\n",
       " 'doc3': 'It worked great for the first few months. Then started having issues with the touch screen. Then the charging port went bad and I had to send it to ASUS for repair. The charging problem was fixed but the touch screen issues were not. It seems to be temperature sensitive-in cooler environments it functions properly but when it\\'s warmer the touch screen won\\'t work at all. Also, the charging port that got replaced is going bad again. This tablet would get five stars if it actually worked properly.\", \\'',\n",
       " 'doc4': 'I\\'ve been using net books for a few years now, finally bought s tablet. I\\'ve had it for over 6mos now and now problems whatsoever. I use it for watching movies, games (emulators), shopping, browsing the web, and I just started editing my gopro videos on it with Kinemaster\", \\'\\', \"I am very surprised at the ease of editing 720p videos from my hero4. I know it\\'s not as good as my big PC or a dedicated video editing machine, but the convenience of this little tablet is what counts. I\\'m just happy to get my videos off my hero4 and onto Vimeo.\", \\'',\n",
       " 'doc5': 'My pre-teen son bought this with his saved money instead of a laptop. He has used it quite a lot. It is a good device. Responsive, good battery life, tough (he\\'s dropped it several times), etc. Would recommend.\", \\'',\n",
       " 'doc6': 'Upgraded from a Nexus 7 older model. You can easily notice the difference: The screen is great, the stero speakers and the rear camera additions are really appreciated and overall it feels fast and responsive, unlike my older Nexus 7 (specially after upgrading to Android L). I guess the only thing I\\'m not thrilled about is the responsiveness of the screen, I have the feeling that my older tablet reacted to a lighter touch compared to this one. Overall I\\'m quite happy with my purchase.\", \\'',\n",
       " 'doc7': \"Too Google controlled.', 'Unable to delete things you do not want to use or at least put them on hold.', 'Google should allow elective suspension.', '\",\n",
       " 'doc8': 'Bricked by an update pushed over the air. This was 100% stock. I loved it for the first year, then this happened 2 months out of warranty. Asus wanted $200 to fix it (more than a new one). Google the problem and you will see it is a widespread issue experienced by hundreds. Asus won\\'t acknowledge the issue. I ended up sending it in just to get the repair estimate and submitted that to American Express which automatically added a year to the warranty when I bought it. I then used the claim money to buy parts on eBay and got it working again. One month later it failed for another common issue. The touch screen became jumpy and unresponsive. Piece of junk I\\'ve wasted too much time on. A shame because I really liked it at first. My dealings with ASUS resulted in a complete loss of confidence with the company. Although some of their products have good reviews (even this one, amazingly), I now avoid ASUS products completely because I\\'m not willing to roll the dice with them again. If ASUS had acknowledged the problem, fixed defective units, and released a revision, it would have cost them a trivial amount of money. It would have been the right thing to do. Instead, they are writing off customers as a less expensive loss.\", \\'',\n",
       " 'doc9': 'do NOT fall for this crappy super slow tablet.. I tried hard , very hard for two weeks to CONVINCE myself that I\\'m too picky , that I\\'m asking too much ... I tried to justify its flaws .. In vein .. I ended up hating that piece of disaster so much, to the point I HAD TO THROW IT IN THE GARBAGE CAN.. instead of returning it.. I thought to give it as a present to a child but soon I realized that no child deserves to get so frustrated by its slugginess and hardware ugliness\", \\''}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_dicionary(text):\n",
    "    count = 1\n",
    "    dictionary = {}\n",
    "    for i in text:\n",
    "    #print(i[6:])\n",
    "        dictionary['doc'+str(count)] = i[4:] #Adding the text to a dictionary with the corresponding doc ids as the key and the text as the value\n",
    "        count += 1\n",
    "    return dictionary\n",
    "document_dictionary = convert_to_dicionary(text_compiled)\n",
    "    \n",
    "document_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the documents, removing stop words and stemming the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this process, we get the set of clean and stemmed words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thi',\n",
       " 'one',\n",
       " 'wa',\n",
       " 'one',\n",
       " 'most',\n",
       " 'power',\n",
       " 'system',\n",
       " '2013',\n",
       " 'still',\n",
       " 'ha',\n",
       " 'some',\n",
       " 'thing',\n",
       " 'like',\n",
       " 'slimport',\n",
       " 'that',\n",
       " 'do',\n",
       " 'plu',\n",
       " 'when',\n",
       " 'compar',\n",
       " 'to',\n",
       " 'more',\n",
       " 'modern',\n",
       " 'but',\n",
       " 'lower',\n",
       " 'profil',\n",
       " 'option',\n",
       " 'from',\n",
       " 'now day',\n",
       " 'screen',\n",
       " 'awesom',\n",
       " 'onli',\n",
       " 'counter back',\n",
       " 'that',\n",
       " 'ridicul',\n",
       " 'even',\n",
       " 'if',\n",
       " 'know',\n",
       " 'ha',\n",
       " 'asu',\n",
       " 'nexu',\n",
       " 'from',\n",
       " 'googl',\n",
       " 'googl',\n",
       " 'doe',\n",
       " 'worst',\n",
       " 'use',\n",
       " 'their',\n",
       " 'own',\n",
       " 'os',\n",
       " 'when',\n",
       " 'we',\n",
       " 'compar',\n",
       " 'with',\n",
       " 'one',\n",
       " 'lg',\n",
       " 'or',\n",
       " 'soni',\n",
       " 'system',\n",
       " 'so',\n",
       " 'hardwar',\n",
       " 'from',\n",
       " 'asu',\n",
       " '5',\n",
       " 'star',\n",
       " 'flawless',\n",
       " 'topnotch',\n",
       " 'gear',\n",
       " 'great',\n",
       " 'price',\n",
       " 'thi',\n",
       " 'still',\n",
       " 'rock',\n",
       " 'even',\n",
       " '2015',\n",
       " 'next',\n",
       " 'year',\n",
       " 'too',\n",
       " 'softwar',\n",
       " 'os',\n",
       " 'from',\n",
       " 'googl',\n",
       " '1',\n",
       " 'star',\n",
       " 'aw',\n",
       " 'even',\n",
       " 'if',\n",
       " 'updat',\n",
       " 'i',\n",
       " 'realli',\n",
       " 'love',\n",
       " 'my',\n",
       " 'nexu',\n",
       " 'my',\n",
       " 'husband',\n",
       " 'surpris',\n",
       " 'me',\n",
       " 'for',\n",
       " 'my',\n",
       " 'birthday',\n",
       " 'year',\n",
       " 'ago',\n",
       " 'with',\n",
       " 'thi',\n",
       " 'i',\n",
       " 'd',\n",
       " 'onli',\n",
       " 'use',\n",
       " 'an',\n",
       " 'iphon',\n",
       " 'befor',\n",
       " 'so',\n",
       " 'i',\n",
       " 'wasn t',\n",
       " 'sure',\n",
       " 'about',\n",
       " 'get',\n",
       " 'use',\n",
       " 'to',\n",
       " 'an',\n",
       " 'android',\n",
       " 'oper',\n",
       " 'system',\n",
       " 'but',\n",
       " 'now',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'it',\n",
       " 'i',\n",
       " 'love',\n",
       " 'have',\n",
       " 'back',\n",
       " 'button',\n",
       " 'i',\n",
       " 'love',\n",
       " 'be',\n",
       " 'abl',\n",
       " 'to',\n",
       " 'move',\n",
       " 'cursor',\n",
       " 'where',\n",
       " 'i',\n",
       " 'want',\n",
       " 'it',\n",
       " 'i',\n",
       " 'like',\n",
       " 'size',\n",
       " 'thi',\n",
       " 'not',\n",
       " 'too',\n",
       " 'big',\n",
       " 'or',\n",
       " 'small',\n",
       " 'i',\n",
       " 'read',\n",
       " 'lot',\n",
       " 'ebook',\n",
       " 'it',\n",
       " 'weight',\n",
       " 'good',\n",
       " 'i',\n",
       " 'immedi',\n",
       " 'put',\n",
       " 'tech',\n",
       " 'armor',\n",
       " 'screen',\n",
       " 'protector',\n",
       " 'devicewear',\n",
       " 'case',\n",
       " 'it',\n",
       " 'to',\n",
       " 'protect',\n",
       " 'it',\n",
       " 'sometim',\n",
       " 'my',\n",
       " 'camera',\n",
       " 'won t',\n",
       " 'work',\n",
       " 'but',\n",
       " 'if',\n",
       " 'i',\n",
       " 'restart',\n",
       " 'devic',\n",
       " 'than',\n",
       " 'it',\n",
       " 'work',\n",
       " 'again',\n",
       " 'fine',\n",
       " 'i',\n",
       " 'have',\n",
       " 'an',\n",
       " 'iphon',\n",
       " 'ipod',\n",
       " 'touch',\n",
       " 'but',\n",
       " 'i',\n",
       " 'much',\n",
       " 'prefer',\n",
       " 'thi',\n",
       " 'to',\n",
       " 'an',\n",
       " 'ipad',\n",
       " 'price',\n",
       " 'wa',\n",
       " 'great',\n",
       " 'for',\n",
       " 'all',\n",
       " 'storag',\n",
       " 'tablet',\n",
       " 'that',\n",
       " 'fast',\n",
       " 'work',\n",
       " 'well',\n",
       " 'it',\n",
       " 'work',\n",
       " 'great',\n",
       " 'for',\n",
       " 'first',\n",
       " 'few',\n",
       " 'month',\n",
       " 'then',\n",
       " 'start',\n",
       " 'have',\n",
       " 'issu',\n",
       " 'with',\n",
       " 'touch',\n",
       " 'screen',\n",
       " 'then',\n",
       " 'charg',\n",
       " 'port',\n",
       " 'went',\n",
       " 'bad',\n",
       " 'i',\n",
       " 'had',\n",
       " 'to',\n",
       " 'send',\n",
       " 'it',\n",
       " 'to',\n",
       " 'asu',\n",
       " 'for',\n",
       " 'repair',\n",
       " 'charg',\n",
       " 'problem',\n",
       " 'wa',\n",
       " 'fix',\n",
       " 'but',\n",
       " 'touch',\n",
       " 'screen',\n",
       " 'issu',\n",
       " 'were',\n",
       " 'not',\n",
       " 'it',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'be',\n",
       " 'temperatur',\n",
       " 'sensitive in',\n",
       " 'cooler',\n",
       " 'environ',\n",
       " 'it',\n",
       " 'function',\n",
       " 'properli',\n",
       " 'but',\n",
       " 'when',\n",
       " 'it',\n",
       " 's',\n",
       " 'warmer',\n",
       " 'touch',\n",
       " 'screen',\n",
       " 'won t',\n",
       " 'work',\n",
       " 'all',\n",
       " 'also',\n",
       " 'charg',\n",
       " 'port',\n",
       " 'that',\n",
       " 'got',\n",
       " 'replac',\n",
       " 'go',\n",
       " 'bad',\n",
       " 'again',\n",
       " 'thi',\n",
       " 'tablet',\n",
       " 'would',\n",
       " 'get',\n",
       " 'five',\n",
       " 'star',\n",
       " 'if',\n",
       " 'it',\n",
       " 'actual',\n",
       " 'work',\n",
       " 'properli',\n",
       " 'i',\n",
       " 've',\n",
       " 'been',\n",
       " 'use',\n",
       " 'net',\n",
       " 'book',\n",
       " 'for',\n",
       " 'few',\n",
       " 'year',\n",
       " 'now',\n",
       " 'final',\n",
       " 'bought',\n",
       " 's',\n",
       " 'tablet',\n",
       " 'i',\n",
       " 've',\n",
       " 'had',\n",
       " 'it',\n",
       " 'for',\n",
       " 'over',\n",
       " '6mo',\n",
       " 'now',\n",
       " 'now',\n",
       " 'problem',\n",
       " 'whatsoev',\n",
       " 'i',\n",
       " 'use',\n",
       " 'it',\n",
       " 'for',\n",
       " 'watch',\n",
       " 'movi',\n",
       " 'game',\n",
       " 'emul',\n",
       " 'shop',\n",
       " 'brows',\n",
       " 'web',\n",
       " 'i',\n",
       " 'just',\n",
       " 'start',\n",
       " 'edit',\n",
       " 'my',\n",
       " 'gopro',\n",
       " 'video',\n",
       " 'it',\n",
       " 'with',\n",
       " 'kinemast',\n",
       " 'i',\n",
       " 'am',\n",
       " 'veri',\n",
       " 'surpris',\n",
       " 'eas',\n",
       " 'edit',\n",
       " '720p',\n",
       " 'video',\n",
       " 'from',\n",
       " 'my',\n",
       " 'hero4',\n",
       " 'i',\n",
       " 'know',\n",
       " 'it',\n",
       " 's',\n",
       " 'not',\n",
       " 'as',\n",
       " 'good',\n",
       " 'as',\n",
       " 'my',\n",
       " 'big',\n",
       " 'pc',\n",
       " 'or',\n",
       " 'dedic',\n",
       " 'video',\n",
       " 'edit',\n",
       " 'machin',\n",
       " 'but',\n",
       " 'conveni',\n",
       " 'thi',\n",
       " 'littl',\n",
       " 'tablet',\n",
       " 'what',\n",
       " 'count',\n",
       " 'i',\n",
       " 'm',\n",
       " 'just',\n",
       " 'happi',\n",
       " 'to',\n",
       " 'get',\n",
       " 'my',\n",
       " 'video',\n",
       " 'off',\n",
       " 'my',\n",
       " 'hero4',\n",
       " 'onto',\n",
       " 'vimeo',\n",
       " 'my',\n",
       " 'pre teen',\n",
       " 'son',\n",
       " 'bought',\n",
       " 'thi',\n",
       " 'with',\n",
       " 'hi',\n",
       " 'save',\n",
       " 'money',\n",
       " 'instead',\n",
       " 'laptop',\n",
       " 'he',\n",
       " 'ha',\n",
       " 'use',\n",
       " 'it',\n",
       " 'quit',\n",
       " 'lot',\n",
       " 'it',\n",
       " 'good',\n",
       " 'devic',\n",
       " 'respons',\n",
       " 'good',\n",
       " 'batteri',\n",
       " 'life',\n",
       " 'tough',\n",
       " 'he',\n",
       " 's',\n",
       " 'drop',\n",
       " 'it',\n",
       " 'sever',\n",
       " 'time',\n",
       " 'etc',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'upgrad',\n",
       " 'from',\n",
       " 'nexu',\n",
       " '7',\n",
       " 'older',\n",
       " 'model',\n",
       " 'you',\n",
       " 'can',\n",
       " 'easili',\n",
       " 'notic',\n",
       " 'differ',\n",
       " 'screen',\n",
       " 'great',\n",
       " 'stero',\n",
       " 'speaker',\n",
       " 'rear',\n",
       " 'camera',\n",
       " 'addit',\n",
       " 'are',\n",
       " 'realli',\n",
       " 'appreci',\n",
       " 'overal',\n",
       " 'it',\n",
       " 'feel',\n",
       " 'fast',\n",
       " 'respons',\n",
       " 'unlik',\n",
       " 'my',\n",
       " 'older',\n",
       " 'nexu',\n",
       " '7',\n",
       " 'special',\n",
       " 'after',\n",
       " 'upgrad',\n",
       " 'to',\n",
       " 'android',\n",
       " 'l',\n",
       " 'i',\n",
       " 'guess',\n",
       " 'onli',\n",
       " 'thing',\n",
       " 'i',\n",
       " 'm',\n",
       " 'not',\n",
       " 'thrill',\n",
       " 'about',\n",
       " 'respons',\n",
       " 'screen',\n",
       " 'i',\n",
       " 'have',\n",
       " 'feel',\n",
       " 'that',\n",
       " 'my',\n",
       " 'older',\n",
       " 'tablet',\n",
       " 'react',\n",
       " 'to',\n",
       " 'lighter',\n",
       " 'touch',\n",
       " 'compar',\n",
       " 'to',\n",
       " 'thi',\n",
       " 'one',\n",
       " 'overal',\n",
       " 'i',\n",
       " 'm',\n",
       " 'quit',\n",
       " 'happi',\n",
       " 'with',\n",
       " 'my',\n",
       " 'purchas',\n",
       " 'too',\n",
       " 'googl',\n",
       " 'control',\n",
       " 'unabl',\n",
       " 'to',\n",
       " 'delet',\n",
       " 'thing',\n",
       " 'you',\n",
       " 'do',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'use',\n",
       " 'or',\n",
       " 'least',\n",
       " 'put',\n",
       " 'them',\n",
       " 'hold',\n",
       " 'googl',\n",
       " 'should',\n",
       " 'allow',\n",
       " 'elect',\n",
       " 'suspens',\n",
       " 'brick',\n",
       " 'by',\n",
       " 'an',\n",
       " 'updat',\n",
       " 'push',\n",
       " 'over',\n",
       " 'air',\n",
       " 'thi',\n",
       " 'wa',\n",
       " '100',\n",
       " 'stock',\n",
       " 'i',\n",
       " 'love',\n",
       " 'it',\n",
       " 'for',\n",
       " 'first',\n",
       " 'year',\n",
       " 'then',\n",
       " 'thi',\n",
       " 'happen',\n",
       " '2',\n",
       " 'month',\n",
       " 'out',\n",
       " 'warranti',\n",
       " 'asu',\n",
       " 'want',\n",
       " '200',\n",
       " 'to',\n",
       " 'fix',\n",
       " 'it',\n",
       " 'more',\n",
       " 'than',\n",
       " 'new',\n",
       " 'one',\n",
       " 'googl',\n",
       " 'problem',\n",
       " 'you',\n",
       " 'will',\n",
       " 'see',\n",
       " 'it',\n",
       " 'widespread',\n",
       " 'issu',\n",
       " 'experienc',\n",
       " 'by',\n",
       " 'hundr',\n",
       " 'asu',\n",
       " 'won t',\n",
       " 'acknowledg',\n",
       " 'issu',\n",
       " 'i',\n",
       " 'end',\n",
       " 'up',\n",
       " 'send',\n",
       " 'it',\n",
       " 'in',\n",
       " 'just',\n",
       " 'to',\n",
       " 'get',\n",
       " 'repair',\n",
       " 'estim',\n",
       " 'submit',\n",
       " 'that',\n",
       " 'to',\n",
       " 'american',\n",
       " 'express',\n",
       " 'which',\n",
       " 'automat',\n",
       " 'ad',\n",
       " 'year',\n",
       " 'to',\n",
       " 'warranti',\n",
       " 'when',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'it',\n",
       " 'i',\n",
       " 'then',\n",
       " 'use',\n",
       " 'claim',\n",
       " 'money',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'part',\n",
       " 'ebay',\n",
       " 'got',\n",
       " 'it',\n",
       " 'work',\n",
       " 'again',\n",
       " 'one',\n",
       " 'month',\n",
       " 'later',\n",
       " 'it',\n",
       " 'fail',\n",
       " 'for',\n",
       " 'anoth',\n",
       " 'common',\n",
       " 'issu',\n",
       " 'touch',\n",
       " 'screen',\n",
       " 'becam',\n",
       " 'jumpi',\n",
       " 'unrespons',\n",
       " 'piec',\n",
       " 'junk',\n",
       " 'i',\n",
       " 've',\n",
       " 'wast',\n",
       " 'too',\n",
       " 'much',\n",
       " 'time',\n",
       " 'shame',\n",
       " 'becaus',\n",
       " 'i',\n",
       " 'realli',\n",
       " 'like',\n",
       " 'it',\n",
       " 'first',\n",
       " 'my',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'asu',\n",
       " 'result',\n",
       " 'in',\n",
       " 'complet',\n",
       " 'loss',\n",
       " 'confid',\n",
       " 'with',\n",
       " 'compani',\n",
       " 'although',\n",
       " 'some',\n",
       " 'their',\n",
       " 'product',\n",
       " 'have',\n",
       " 'good',\n",
       " 'review',\n",
       " 'even',\n",
       " 'thi',\n",
       " 'one',\n",
       " 'amazingli',\n",
       " 'i',\n",
       " 'now',\n",
       " 'avoid',\n",
       " 'asu',\n",
       " 'product',\n",
       " 'complet',\n",
       " 'becaus',\n",
       " 'i',\n",
       " 'm',\n",
       " 'not',\n",
       " 'will',\n",
       " 'to',\n",
       " 'roll',\n",
       " 'dice',\n",
       " 'with',\n",
       " 'them',\n",
       " 'again',\n",
       " 'if',\n",
       " 'asu',\n",
       " 'had',\n",
       " 'acknowledg',\n",
       " 'problem',\n",
       " 'fix',\n",
       " 'defect',\n",
       " 'unit',\n",
       " 'releas',\n",
       " 'revis',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'cost',\n",
       " 'them',\n",
       " 'trivial',\n",
       " 'amount',\n",
       " 'money',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'right',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'do',\n",
       " 'instead',\n",
       " 'they',\n",
       " 'are',\n",
       " 'write',\n",
       " 'off',\n",
       " 'custom',\n",
       " 'as',\n",
       " 'less',\n",
       " 'expens',\n",
       " 'loss',\n",
       " 'do',\n",
       " 'not',\n",
       " 'fall',\n",
       " 'for',\n",
       " 'thi',\n",
       " 'crappi',\n",
       " 'super',\n",
       " 'slow',\n",
       " 'tablet',\n",
       " 'i',\n",
       " 'tri',\n",
       " 'hard',\n",
       " 'veri',\n",
       " 'hard',\n",
       " 'for',\n",
       " 'two',\n",
       " 'week',\n",
       " 'to',\n",
       " 'convinc',\n",
       " 'myself',\n",
       " 'that',\n",
       " 'i',\n",
       " 'm',\n",
       " 'too',\n",
       " 'picki',\n",
       " 'that',\n",
       " 'i',\n",
       " 'm',\n",
       " 'ask',\n",
       " 'too',\n",
       " 'much',\n",
       " 'i',\n",
       " 'tri',\n",
       " 'to',\n",
       " 'justifi',\n",
       " 'it',\n",
       " 'flaw',\n",
       " 'in',\n",
       " 'vein',\n",
       " 'i',\n",
       " 'end',\n",
       " 'up',\n",
       " 'hate',\n",
       " 'that',\n",
       " 'piec',\n",
       " 'disast',\n",
       " 'so',\n",
       " 'much',\n",
       " 'to',\n",
       " 'point',\n",
       " 'i',\n",
       " 'had',\n",
       " 'to',\n",
       " 'throw',\n",
       " 'it',\n",
       " 'in',\n",
       " 'garbag',\n",
       " 'can',\n",
       " 'instead',\n",
       " 'return',\n",
       " 'it',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'to',\n",
       " 'give',\n",
       " 'it',\n",
       " 'as',\n",
       " 'present',\n",
       " 'to',\n",
       " 'child',\n",
       " 'but',\n",
       " 'soon',\n",
       " 'i',\n",
       " 'realiz',\n",
       " 'that',\n",
       " 'no',\n",
       " 'child',\n",
       " 'deserv',\n",
       " 'to',\n",
       " 'get',\n",
       " 'so',\n",
       " 'frustrat',\n",
       " 'by',\n",
       " 'it',\n",
       " 'sluggi',\n",
       " 'hardwar',\n",
       " 'ugli',\n",
       " 'thi',\n",
       " 'great',\n",
       " 'tablet',\n",
       " 'doe',\n",
       " 'everyth',\n",
       " 'i',\n",
       " 'could',\n",
       " 'want',\n",
       " 'it',\n",
       " 'to',\n",
       " 'i',\n",
       " 'use',\n",
       " 'it',\n",
       " 'mainli',\n",
       " 'as',\n",
       " 'an',\n",
       " 'e read',\n",
       " 'but',\n",
       " 'it',\n",
       " 's',\n",
       " 'nice',\n",
       " 'to',\n",
       " 'have',\n",
       " 'internet',\n",
       " 'game',\n",
       " 'same',\n",
       " 'devic']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "    \n",
    "def stemming_and_stopwords_removal(words):\n",
    "    stop_words = ['the', 'is', 'at', 'of', 'on', 'and', 'a']\n",
    "    #stemmer = nltk.stem.snowball.SnowballStemmer(\"english\")\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    final_arr = []\n",
    "    for v in nltk.tokenize.word_tokenize(words): #removing non alphanumeric characters, stemming the words and converting all text to lower case\n",
    "        v = re.sub(\"[^a-zA-Z0-9]+\", \" \", v)\n",
    "        v = v.lower()\n",
    "        v = v.replace(\",\",\"\")\n",
    "        v = v.replace('',\"\")\n",
    "        v = v.strip()\n",
    "        stemmed = stemmer.stem(v)\n",
    "        if stemmed not in stop_words and stemmed and stemmed!= 'dict valu':\n",
    "        #if stemmed and stemmed!= 'dict valu':\n",
    "            final_arr.append(stemmed) \n",
    "\n",
    "    return final_arr\n",
    "\n",
    "final_arr = stemming_and_stopwords_removal(str(document_dictionary.values()))\n",
    "final_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the clean words in a dictionary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is done for store the dictionary in a clean format without any stopwords and non alphanumeric characters. This helps in creating the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 'thi one wa one most power system 2013 still ha some thing like slimport that do plu when compar to more modern but lower profil option from now day screen awesom onli counter back that ridicul even if know ha asu nexu from googl googl doe worst use their own os when we compar with one lg or soni system so hardwar from asu 5 star flawless topnotch gear great price thi still rock even 2015 next year too softwar os from googl 1 star aw even if updat',\n",
       " 'doc10': 'thi great tablet doe everyth i could want it to i use it mainli as an e read but it s nice to have internet game same devic',\n",
       " 'doc2': 'i realli love my nexu my husband surpris me for my birthday year ago with thi i d onli use an iphon befor so i wa n t sure about get use to an android oper system but now i prefer it i love have back button i love be abl to move cursor where i want it i like size thi not too big or small i read lot ebook it weight good i immedi put tech armor screen protector devicewear case it to protect it sometim my camera wo n t work but if i restart devic than it work again fine i have an iphon ipod touch but i much prefer thi to an ipad price wa great for all storag tablet that fast work well',\n",
       " 'doc3': 'it work great for first few month then start have issu with touch screen then charg port went bad i had to send it to asu for repair charg problem wa fix but touch screen issu were not it seem to be temperatur sensitive in cooler environ it function properli but when it s warmer touch screen wo n t work all also charg port that got replac go bad again thi tablet would get five star if it actual work properli',\n",
       " 'doc4': 'i ve been use net book for few year now final bought s tablet i ve had it for over 6mo now now problem whatsoev i use it for watch movi game emul shop brows web i just start edit my gopro video it with kinemast i am veri surpris eas edit 720p video from my hero4 i know it s not as good as my big pc or dedic video edit machin but conveni thi littl tablet what count i m just happi to get my video off my hero4 onto vimeo',\n",
       " 'doc5': 'my pre teen son bought thi with hi save money instead laptop he ha use it quit lot it good devic respons good batteri life tough he s drop it sever time etc would recommend',\n",
       " 'doc6': 'upgrad from nexu 7 older model you can easili notic differ screen great stero speaker rear camera addit are realli appreci overal it feel fast respons unlik my older nexu 7 special after upgrad to android l i guess onli thing i m not thrill about respons screen i have feel that my older tablet react to lighter touch compar to thi one overal i m quit happi with my purchas',\n",
       " 'doc7': 'too googl control unabl to delet thing you do not want to use or least put them hold googl should allow elect suspens',\n",
       " 'doc8': 'brick by an updat push over air thi wa 100 stock i love it for first year then thi happen 2 month out warranti asu want 200 to fix it more than new one googl problem you will see it widespread issu experienc by hundr asu wo n t acknowledg issu i end up send it in just to get repair estim submit that to american express which automat ad year to warranti when i bought it i then use claim money to buy part ebay got it work again one month later it fail for anoth common issu touch screen becam jumpi unrespons piec junk i ve wast too much time shame becaus i realli like it first my deal with asu result in complet loss confid with compani although some their product have good review even thi one amazingli i now avoid asu product complet becaus i m not will to roll dice with them again if asu had acknowledg problem fix defect unit releas revis it would have cost them trivial amount money it would have been right thing to do instead they are write off custom as less expens loss',\n",
       " 'doc9': 'do not fall for thi crappi super slow tablet i tri hard veri hard for two week to convinc myself that i m too picki that i m ask too much i tri to justifi it flaw in vein i end up hate that piec disast so much to point i had to throw it in garbag can instead return it i thought to give it as present to child but soon i realiz that no child deserv to get so frustrat by it sluggi hardwar ugli'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dd = {}\n",
    "for k,v in document_dictionary.items():\n",
    "    #v = \" \".join(stemmer.stem(i.replace(\",\",\"\").replace(\"'\",'').strip()) for i in nltk.tokenize.word_tokenize(v) if i not in stop_words)\n",
    "    v =  \" \".join(stemming_and_stopwords_removal(v))\n",
    "    clean_dd[k] = v\n",
    "    #print(v)\n",
    "\n",
    "        \n",
    "clean_dd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the terms in the cleaned bag of words and the clean dictionary created an inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for creating the inverted index is because it provides a quick lookup in order to retrieve the terms and the documents where the terms appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'1': ['doc1'],\n",
       "             '100': ['doc8'],\n",
       "             '2': ['doc8'],\n",
       "             '200': ['doc8'],\n",
       "             '2013': ['doc1'],\n",
       "             '2015': ['doc1'],\n",
       "             '5': ['doc1'],\n",
       "             '6mo': ['doc4'],\n",
       "             '7': ['doc6'],\n",
       "             '720p': ['doc4'],\n",
       "             'abl': ['doc2'],\n",
       "             'about': ['doc2', 'doc6'],\n",
       "             'acknowledg': ['doc8'],\n",
       "             'actual': ['doc3'],\n",
       "             'ad': ['doc8'],\n",
       "             'addit': ['doc6'],\n",
       "             'after': ['doc6'],\n",
       "             'again': ['doc2', 'doc3', 'doc8'],\n",
       "             'ago': ['doc2'],\n",
       "             'air': ['doc8'],\n",
       "             'all': ['doc2', 'doc3'],\n",
       "             'allow': ['doc7'],\n",
       "             'also': ['doc3'],\n",
       "             'although': ['doc8'],\n",
       "             'am': ['doc4'],\n",
       "             'amazingli': ['doc8'],\n",
       "             'american': ['doc8'],\n",
       "             'amount': ['doc8'],\n",
       "             'an': ['doc2', 'doc8', 'doc10'],\n",
       "             'android': ['doc2', 'doc6'],\n",
       "             'anoth': ['doc8'],\n",
       "             'appreci': ['doc6'],\n",
       "             'are': ['doc6', 'doc8'],\n",
       "             'armor': ['doc2'],\n",
       "             'as': ['doc4', 'doc8', 'doc9', 'doc10'],\n",
       "             'ask': ['doc9'],\n",
       "             'asu': ['doc1', 'doc3', 'doc8'],\n",
       "             'automat': ['doc8'],\n",
       "             'avoid': ['doc8'],\n",
       "             'aw': ['doc1'],\n",
       "             'awesom': ['doc1'],\n",
       "             'back': ['doc1', 'doc2'],\n",
       "             'bad': ['doc3'],\n",
       "             'batteri': ['doc5'],\n",
       "             'be': ['doc2', 'doc3'],\n",
       "             'becam': ['doc8'],\n",
       "             'becaus': ['doc8'],\n",
       "             'been': ['doc4', 'doc8'],\n",
       "             'befor': ['doc2'],\n",
       "             'big': ['doc2', 'doc4'],\n",
       "             'birthday': ['doc2'],\n",
       "             'book': ['doc4'],\n",
       "             'bought': ['doc4', 'doc5', 'doc8'],\n",
       "             'brick': ['doc8'],\n",
       "             'brows': ['doc4'],\n",
       "             'but': ['doc1', 'doc2', 'doc3', 'doc4', 'doc9', 'doc10'],\n",
       "             'button': ['doc2'],\n",
       "             'buy': ['doc8'],\n",
       "             'by': ['doc8', 'doc9'],\n",
       "             'camera': ['doc2', 'doc6'],\n",
       "             'can': ['doc6', 'doc9'],\n",
       "             'case': ['doc2'],\n",
       "             'charg': ['doc3'],\n",
       "             'child': ['doc9'],\n",
       "             'claim': ['doc8'],\n",
       "             'common': ['doc8'],\n",
       "             'compani': ['doc8'],\n",
       "             'compar': ['doc1', 'doc6'],\n",
       "             'complet': ['doc8'],\n",
       "             'confid': ['doc8'],\n",
       "             'control': ['doc7'],\n",
       "             'conveni': ['doc4'],\n",
       "             'convinc': ['doc9'],\n",
       "             'cooler': ['doc3'],\n",
       "             'cost': ['doc8'],\n",
       "             'could': ['doc10'],\n",
       "             'count': ['doc4'],\n",
       "             'crappi': ['doc9'],\n",
       "             'cursor': ['doc2'],\n",
       "             'custom': ['doc8'],\n",
       "             'd': ['doc2'],\n",
       "             'deal': ['doc8'],\n",
       "             'dedic': ['doc4'],\n",
       "             'defect': ['doc8'],\n",
       "             'delet': ['doc7'],\n",
       "             'deserv': ['doc9'],\n",
       "             'devic': ['doc2', 'doc5', 'doc10'],\n",
       "             'devicewear': ['doc2'],\n",
       "             'dice': ['doc8'],\n",
       "             'differ': ['doc6'],\n",
       "             'disast': ['doc9'],\n",
       "             'do': ['doc1', 'doc7', 'doc8', 'doc9'],\n",
       "             'doe': ['doc1', 'doc10'],\n",
       "             'drop': ['doc5'],\n",
       "             'eas': ['doc4'],\n",
       "             'easili': ['doc6'],\n",
       "             'ebay': ['doc8'],\n",
       "             'ebook': ['doc2'],\n",
       "             'edit': ['doc4'],\n",
       "             'elect': ['doc7'],\n",
       "             'emul': ['doc4'],\n",
       "             'end': ['doc8', 'doc9'],\n",
       "             'environ': ['doc3'],\n",
       "             'estim': ['doc8'],\n",
       "             'etc': ['doc5'],\n",
       "             'even': ['doc1', 'doc8'],\n",
       "             'everyth': ['doc10'],\n",
       "             'expens': ['doc8'],\n",
       "             'experienc': ['doc8'],\n",
       "             'express': ['doc8'],\n",
       "             'fail': ['doc8'],\n",
       "             'fall': ['doc9'],\n",
       "             'fast': ['doc2', 'doc6'],\n",
       "             'feel': ['doc6'],\n",
       "             'few': ['doc3', 'doc4'],\n",
       "             'final': ['doc4'],\n",
       "             'fine': ['doc2'],\n",
       "             'first': ['doc3', 'doc8'],\n",
       "             'five': ['doc3'],\n",
       "             'fix': ['doc3', 'doc8'],\n",
       "             'flaw': ['doc9'],\n",
       "             'flawless': ['doc1'],\n",
       "             'for': ['doc2', 'doc3', 'doc4', 'doc8', 'doc9'],\n",
       "             'from': ['doc1', 'doc4', 'doc6'],\n",
       "             'frustrat': ['doc9'],\n",
       "             'function': ['doc3'],\n",
       "             'game': ['doc4', 'doc10'],\n",
       "             'garbag': ['doc9'],\n",
       "             'gear': ['doc1'],\n",
       "             'get': ['doc2', 'doc3', 'doc4', 'doc8', 'doc9'],\n",
       "             'give': ['doc9'],\n",
       "             'go': ['doc3'],\n",
       "             'good': ['doc2', 'doc4', 'doc5', 'doc8'],\n",
       "             'googl': ['doc1', 'doc7', 'doc8'],\n",
       "             'gopro': ['doc4'],\n",
       "             'got': ['doc3', 'doc8'],\n",
       "             'great': ['doc1', 'doc2', 'doc3', 'doc6', 'doc10'],\n",
       "             'guess': ['doc6'],\n",
       "             'ha': ['doc1', 'doc5'],\n",
       "             'had': ['doc3', 'doc4', 'doc8', 'doc9'],\n",
       "             'happen': ['doc8'],\n",
       "             'happi': ['doc4', 'doc6'],\n",
       "             'hard': ['doc9'],\n",
       "             'hardwar': ['doc1', 'doc9'],\n",
       "             'hate': ['doc9'],\n",
       "             'have': ['doc2', 'doc3', 'doc6', 'doc8', 'doc10'],\n",
       "             'he': ['doc5'],\n",
       "             'hero4': ['doc4'],\n",
       "             'hi': ['doc5'],\n",
       "             'hold': ['doc7'],\n",
       "             'hundr': ['doc8'],\n",
       "             'husband': ['doc2'],\n",
       "             'i': ['doc2', 'doc3', 'doc4', 'doc6', 'doc8', 'doc9', 'doc10'],\n",
       "             'if': ['doc1', 'doc2', 'doc3', 'doc8'],\n",
       "             'immedi': ['doc2'],\n",
       "             'in': ['doc3', 'doc8', 'doc9'],\n",
       "             'instead': ['doc5', 'doc8', 'doc9'],\n",
       "             'internet': ['doc10'],\n",
       "             'ipad': ['doc2'],\n",
       "             'iphon': ['doc2'],\n",
       "             'ipod': ['doc2'],\n",
       "             'issu': ['doc3', 'doc8'],\n",
       "             'it': ['doc2',\n",
       "              'doc3',\n",
       "              'doc4',\n",
       "              'doc5',\n",
       "              'doc6',\n",
       "              'doc8',\n",
       "              'doc9',\n",
       "              'doc10'],\n",
       "             'jumpi': ['doc8'],\n",
       "             'junk': ['doc8'],\n",
       "             'just': ['doc4', 'doc8'],\n",
       "             'justifi': ['doc9'],\n",
       "             'kinemast': ['doc4'],\n",
       "             'know': ['doc1', 'doc4'],\n",
       "             'l': ['doc6'],\n",
       "             'laptop': ['doc5'],\n",
       "             'later': ['doc8'],\n",
       "             'least': ['doc7'],\n",
       "             'less': ['doc8'],\n",
       "             'lg': ['doc1'],\n",
       "             'life': ['doc5'],\n",
       "             'lighter': ['doc6'],\n",
       "             'like': ['doc1', 'doc2', 'doc8'],\n",
       "             'littl': ['doc4'],\n",
       "             'loss': ['doc8'],\n",
       "             'lot': ['doc2', 'doc5'],\n",
       "             'love': ['doc2', 'doc8'],\n",
       "             'lower': ['doc1'],\n",
       "             'm': ['doc4', 'doc6', 'doc8', 'doc9'],\n",
       "             'machin': ['doc4'],\n",
       "             'mainli': ['doc10'],\n",
       "             'me': ['doc2'],\n",
       "             'model': ['doc6'],\n",
       "             'modern': ['doc1'],\n",
       "             'money': ['doc5', 'doc8'],\n",
       "             'month': ['doc3', 'doc8'],\n",
       "             'more': ['doc1', 'doc8'],\n",
       "             'most': ['doc1'],\n",
       "             'move': ['doc2'],\n",
       "             'movi': ['doc4'],\n",
       "             'much': ['doc2', 'doc8', 'doc9'],\n",
       "             'my': ['doc2', 'doc4', 'doc5', 'doc6', 'doc8'],\n",
       "             'myself': ['doc9'],\n",
       "             'net': ['doc4'],\n",
       "             'new': ['doc8'],\n",
       "             'next': ['doc1'],\n",
       "             'nexu': ['doc1', 'doc2', 'doc6'],\n",
       "             'nice': ['doc10'],\n",
       "             'no': ['doc9'],\n",
       "             'not': ['doc2', 'doc3', 'doc4', 'doc6', 'doc7', 'doc8', 'doc9'],\n",
       "             'notic': ['doc6'],\n",
       "             'now': ['doc1', 'doc2', 'doc4', 'doc8'],\n",
       "             'off': ['doc4', 'doc8'],\n",
       "             'older': ['doc6'],\n",
       "             'one': ['doc1', 'doc6', 'doc8'],\n",
       "             'onli': ['doc1', 'doc2', 'doc6'],\n",
       "             'onto': ['doc4'],\n",
       "             'oper': ['doc2'],\n",
       "             'option': ['doc1'],\n",
       "             'or': ['doc1', 'doc2', 'doc4', 'doc7'],\n",
       "             'os': ['doc1'],\n",
       "             'out': ['doc8'],\n",
       "             'over': ['doc4', 'doc8'],\n",
       "             'overal': ['doc6'],\n",
       "             'own': ['doc1'],\n",
       "             'part': ['doc8'],\n",
       "             'pc': ['doc4'],\n",
       "             'picki': ['doc9'],\n",
       "             'piec': ['doc8', 'doc9'],\n",
       "             'plu': ['doc1'],\n",
       "             'point': ['doc9'],\n",
       "             'port': ['doc3'],\n",
       "             'power': ['doc1'],\n",
       "             'prefer': ['doc2'],\n",
       "             'present': ['doc9'],\n",
       "             'price': ['doc1', 'doc2'],\n",
       "             'problem': ['doc3', 'doc4', 'doc8'],\n",
       "             'product': ['doc8'],\n",
       "             'profil': ['doc1'],\n",
       "             'properli': ['doc3'],\n",
       "             'protect': ['doc2'],\n",
       "             'protector': ['doc2'],\n",
       "             'purchas': ['doc6'],\n",
       "             'push': ['doc8'],\n",
       "             'put': ['doc2', 'doc7'],\n",
       "             'quit': ['doc5', 'doc6'],\n",
       "             'react': ['doc6'],\n",
       "             'read': ['doc2', 'doc10'],\n",
       "             'realiz': ['doc9'],\n",
       "             'realli': ['doc2', 'doc6', 'doc8'],\n",
       "             'rear': ['doc6'],\n",
       "             'recommend': ['doc5'],\n",
       "             'releas': ['doc8'],\n",
       "             'repair': ['doc3', 'doc8'],\n",
       "             'replac': ['doc3'],\n",
       "             'respons': ['doc5', 'doc6'],\n",
       "             'restart': ['doc2'],\n",
       "             'result': ['doc8'],\n",
       "             'return': ['doc9'],\n",
       "             'review': ['doc8'],\n",
       "             'revis': ['doc8'],\n",
       "             'ridicul': ['doc1'],\n",
       "             'right': ['doc8'],\n",
       "             'rock': ['doc1'],\n",
       "             'roll': ['doc8'],\n",
       "             's': ['doc3', 'doc4', 'doc5', 'doc10'],\n",
       "             'same': ['doc10'],\n",
       "             'save': ['doc5'],\n",
       "             'screen': ['doc1', 'doc2', 'doc3', 'doc6', 'doc8'],\n",
       "             'see': ['doc8'],\n",
       "             'seem': ['doc3'],\n",
       "             'send': ['doc3', 'doc8'],\n",
       "             'sever': ['doc5'],\n",
       "             'shame': ['doc8'],\n",
       "             'shop': ['doc4'],\n",
       "             'should': ['doc7'],\n",
       "             'size': ['doc2'],\n",
       "             'slimport': ['doc1'],\n",
       "             'slow': ['doc9'],\n",
       "             'sluggi': ['doc9'],\n",
       "             'small': ['doc2'],\n",
       "             'so': ['doc1', 'doc2', 'doc9'],\n",
       "             'softwar': ['doc1'],\n",
       "             'some': ['doc1', 'doc8'],\n",
       "             'sometim': ['doc2'],\n",
       "             'son': ['doc5'],\n",
       "             'soni': ['doc1'],\n",
       "             'soon': ['doc9'],\n",
       "             'speaker': ['doc6'],\n",
       "             'special': ['doc6'],\n",
       "             'star': ['doc1', 'doc3'],\n",
       "             'start': ['doc3', 'doc4'],\n",
       "             'stero': ['doc6'],\n",
       "             'still': ['doc1'],\n",
       "             'stock': ['doc8'],\n",
       "             'storag': ['doc2'],\n",
       "             'submit': ['doc8'],\n",
       "             'super': ['doc9'],\n",
       "             'sure': ['doc2'],\n",
       "             'surpris': ['doc2', 'doc4'],\n",
       "             'suspens': ['doc7'],\n",
       "             'system': ['doc1', 'doc2'],\n",
       "             'tablet': ['doc2', 'doc3', 'doc4', 'doc6', 'doc9', 'doc10'],\n",
       "             'tech': ['doc2'],\n",
       "             'temperatur': ['doc3'],\n",
       "             'than': ['doc2', 'doc8'],\n",
       "             'that': ['doc1', 'doc2', 'doc3', 'doc6', 'doc8', 'doc9'],\n",
       "             'their': ['doc1', 'doc8'],\n",
       "             'them': ['doc7', 'doc8'],\n",
       "             'then': ['doc3', 'doc8'],\n",
       "             'they': ['doc8'],\n",
       "             'thi': ['doc1',\n",
       "              'doc2',\n",
       "              'doc3',\n",
       "              'doc4',\n",
       "              'doc5',\n",
       "              'doc6',\n",
       "              'doc8',\n",
       "              'doc9',\n",
       "              'doc10'],\n",
       "             'thing': ['doc1', 'doc6', 'doc7', 'doc8'],\n",
       "             'thought': ['doc9'],\n",
       "             'thrill': ['doc6'],\n",
       "             'throw': ['doc9'],\n",
       "             'time': ['doc5', 'doc8'],\n",
       "             'to': ['doc1',\n",
       "              'doc2',\n",
       "              'doc3',\n",
       "              'doc4',\n",
       "              'doc6',\n",
       "              'doc7',\n",
       "              'doc8',\n",
       "              'doc9',\n",
       "              'doc10'],\n",
       "             'too': ['doc1', 'doc2', 'doc7', 'doc8', 'doc9'],\n",
       "             'topnotch': ['doc1'],\n",
       "             'touch': ['doc2', 'doc3', 'doc6', 'doc8'],\n",
       "             'tough': ['doc5'],\n",
       "             'tri': ['doc9'],\n",
       "             'trivial': ['doc8'],\n",
       "             'two': ['doc9'],\n",
       "             'ugli': ['doc9'],\n",
       "             'unabl': ['doc7'],\n",
       "             'unit': ['doc8'],\n",
       "             'unlik': ['doc6'],\n",
       "             'unrespons': ['doc8'],\n",
       "             'up': ['doc8', 'doc9'],\n",
       "             'updat': ['doc1', 'doc8'],\n",
       "             'upgrad': ['doc6'],\n",
       "             'use': ['doc1', 'doc2', 'doc4', 'doc5', 'doc7', 'doc8', 'doc10'],\n",
       "             've': ['doc4', 'doc8'],\n",
       "             'vein': ['doc9'],\n",
       "             'veri': ['doc4', 'doc9'],\n",
       "             'video': ['doc4'],\n",
       "             'vimeo': ['doc4'],\n",
       "             'wa': ['doc1', 'doc2', 'doc3', 'doc8'],\n",
       "             'want': ['doc2', 'doc7', 'doc8', 'doc10'],\n",
       "             'warmer': ['doc3'],\n",
       "             'warranti': ['doc8'],\n",
       "             'wast': ['doc8'],\n",
       "             'watch': ['doc4'],\n",
       "             'we': ['doc1'],\n",
       "             'web': ['doc4'],\n",
       "             'week': ['doc9'],\n",
       "             'weight': ['doc2'],\n",
       "             'well': ['doc2'],\n",
       "             'went': ['doc3'],\n",
       "             'were': ['doc3'],\n",
       "             'what': ['doc4'],\n",
       "             'whatsoev': ['doc4'],\n",
       "             'when': ['doc1', 'doc3', 'doc8'],\n",
       "             'where': ['doc2'],\n",
       "             'which': ['doc8'],\n",
       "             'widespread': ['doc8'],\n",
       "             'will': ['doc8'],\n",
       "             'with': ['doc1', 'doc2', 'doc3', 'doc4', 'doc5', 'doc6', 'doc8'],\n",
       "             'work': ['doc2', 'doc3', 'doc8'],\n",
       "             'worst': ['doc1'],\n",
       "             'would': ['doc3', 'doc5', 'doc8'],\n",
       "             'write': ['doc8'],\n",
       "             'year': ['doc1', 'doc2', 'doc4', 'doc8'],\n",
       "             'you': ['doc6', 'doc7', 'doc8']})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_inverted_index_dictionary(final):\n",
    "    my_dict = defaultdict(list)\n",
    "    for k,v in clean_dd.items():\n",
    "        word = nltk.tokenize.word_tokenize(v)\n",
    "        for j in range(len(word)):\n",
    "            for i in final:\n",
    "                if i == word[j] and k not in my_dict[i]: #adding the words as the key and the doc where it appears as the value\n",
    "                    my_dict[i].append(k)\n",
    "    return my_dict\n",
    "#stemming_and_stopwords_removal(dictionary,stemmer,stop_words)\n",
    "\n",
    "inverted_index = convert_to_inverted_index_dictionary(set(final_arr))\n",
    "inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the positional inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I have taken the raw document text and have just stemmed the words without cleaning the documents. I have done this in order to retain the original position of each word. The reason for stemming was to match each word with the raw text in the dictionary, since I have already cleaned and stemmed the bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 'thi one wa one of the most power system on 2013  and still ha some thing like slimport that do a plu when is compar to more modern but lower profil option from now-day .   the screen is awesom  the onli counter-back is that ridicul even if is know ha the asu nexu  from googl   googl doe the worst use of their own OS  when we compar with the one on LG or soni system .   So the hardwar from asu = 5 star  flawless a topnotch gear at great price  thi still rock even on 2015 and next year too .   softwar  OS from google= 1 star  aw even if is updat .   ',\n",
       " 'doc10': 'thi is a great tablet and doe everyth I could want it to . I use it mainli as an e-read  but it s nice to have internet and game on the same devic .   ',\n",
       " 'doc2': 'I realli love my nexu ! My husband surpris me for my birthday a year ago with thi . I d onli use an iphon befor so I wa nt sure about get use to an android oper system but now I prefer it . I love have a back button ! I love be abl to move the cursor where I want it . I like the size of thi  not too big or small . I read a lot of ebook and it weight is good . I immedi put a tech armor screen protector and devicewear case on it to protect it . sometim my camera wo nt work but if I restart the devic than it work again fine . I have an iphon and ipod touch but I much prefer thi to an ipad . the price wa great for all the storag and a tablet that is fast and work well .   ',\n",
       " 'doc3': 'It work great for the first few month . then start have issu with the touch screen . then the charg port went bad and I had to send it to asu for repair . the charg problem wa fix but the touch screen issu were not . It seem to be temperatur sensitive-in cooler environ it function properli but when it s warmer the touch screen wo nt work at all . also  the charg port that got replac is go bad again . thi tablet would get five star if it actual work properli .   ',\n",
       " 'doc4': 'I ve been use net book for a few year now  final bought s tablet . I ve had it for over 6mo now and now problem whatsoev . I use it for watch movi  game ( emul )  shop  brows the web  and I just start edit my gopro video on it with kinemast    I am veri surpris at the eas of edit 720p video from my hero4 . I know it s not as good as my big PC or a dedic video edit machin  but the conveni of thi littl tablet is what count . I m just happi to get my video off my hero4 and onto vimeo .   ',\n",
       " 'doc5': 'My pre-teen son bought thi with hi save money instead of a laptop . He ha use it quit a lot . It is a good devic . respons  good batteri life  tough ( he s drop it sever time )  etc . would recommend .   ',\n",
       " 'doc6': 'upgrad from a nexu 7 older model . you can easili notic the differ : the screen is great  the stero speaker and the rear camera addit are realli appreci and overal it feel fast and respons  unlik my older nexu 7 ( special after upgrad to android L ) . I guess the onli thing I m not thrill about is the respons of the screen  I have the feel that my older tablet react to a lighter touch compar to thi one . overal I m quit happi with my purchas .   ',\n",
       " 'doc7': 'too googl control .   unabl to delet thing you do not want to use or at least put them on hold .   googl should allow elect suspens .   ',\n",
       " 'doc8': 'brick by an updat push over the air . thi wa 100 % stock . I love it for the first year  then thi happen 2 month out of warranti . asu want $ 200 to fix it ( more than a new one ) . googl the problem and you will see it is a widespread issu experienc by hundr . asu wo nt acknowledg the issu . I end up send it in just to get the repair estim and submit that to american express which automat ad a year to the warranti when I bought it . I then use the claim money to buy part on ebay and got it work again . one month later it fail for anoth common issu . the touch screen becam jumpi and unrespons . piec of junk I ve wast too much time on . A shame becaus I realli like it at first . My deal with asu result in a complet loss of confid with the compani . although some of their product have good review ( even thi one  amazingli )  I now avoid asu product complet becaus I m not will to roll the dice with them again . If asu had acknowledg the problem  fix defect unit  and releas a revis  it would have cost them a trivial amount of money . It would have been the right thing to do . instead  they are write off custom as a less expens loss .   ',\n",
       " 'doc9': 'do not fall for thi crappi super slow tablet.. I tri hard  veri hard for two week to convinc myself that I m too picki  that I m ask too much ... I tri to justifi it flaw .. In vein .. I end up hate that piec of disast so much  to the point I had TO throw IT IN the garbag can.. instead of return it.. I thought to give it as a present to a child but soon I realiz that no child deserv to get so frustrat by it sluggi and hardwar ugli   '}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs = []\n",
    "for i in docs:\n",
    "    if i.strip():\n",
    "        i = i.replace(\"\\n\",\"\")\n",
    "        new_docs.append(i)\n",
    "    \n",
    "\n",
    "new_docs\n",
    "\n",
    "lines = re.compile('<DOC \\d+>' \"(.*?)\" '</DOC>', re.DOTALL |  re.IGNORECASE ).findall(str(new_docs))\n",
    "#lines = re.findall(r'(<DOC \\d+>(.*?)</DOC>)', str(new_docs))\n",
    "raw_text= []\n",
    "for i in lines:\n",
    "        i = i.rstrip()\n",
    "        raw_text.append(i)\n",
    "\n",
    "dd = {}\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "count = 1\n",
    "for i in raw_text: #Stemming the raw text\n",
    "    v = \" \".join(stemmer.stem(j.replace(\",\",\"\").replace(\"'\",'').replace(\"``\",\"\").rstrip()) for j in nltk.tokenize.word_tokenize(i[4:]))\n",
    "    dd['doc'+str(count)] = v\n",
    "    count += 1\n",
    "dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {('1', 1): [['doc1', [106], 1]],\n",
       "             ('100', 1): [['doc8', [11], 1]],\n",
       "             ('2', 1): [['doc8', [25], 1]],\n",
       "             ('200', 1): [['doc8', [34], 1]],\n",
       "             ('2013', 1): [['doc1', [10], 1]],\n",
       "             ('2015', 1): [['doc1', [96], 1]],\n",
       "             ('5', 1): [['doc1', [82], 1]],\n",
       "             ('6mo', 1): [['doc4', [22], 1]],\n",
       "             ('7', 1): [['doc6', [4, 41], 2]],\n",
       "             ('720p', 1): [['doc4', [64], 1]],\n",
       "             ('abl', 1): [['doc2', [55], 1]],\n",
       "             ('about', 2): [['doc2', [31], 1], ['doc6', [60], 1]],\n",
       "             ('acknowledg', 1): [['doc8', [65, 207], 2]],\n",
       "             ('actual', 1): [['doc3', [93], 1]],\n",
       "             ('ad', 1): [['doc8', [89], 1]],\n",
       "             ('addit', 1): [['doc6', [26], 1]],\n",
       "             ('after', 1): [['doc6', [44], 1]],\n",
       "             ('again', 3): [['doc2', [121], 1],\n",
       "              ['doc3', [83], 1],\n",
       "              ['doc8', [115, 202], 2]],\n",
       "             ('ago', 1): [['doc2', [15], 1]],\n",
       "             ('air', 1): [['doc8', [7], 1]],\n",
       "             ('all', 2): [['doc2', [145], 1], ['doc3', [71], 1]],\n",
       "             ('allow', 1): [['doc7', [24], 1]],\n",
       "             ('also', 1): [['doc3', [73], 1]],\n",
       "             ('although', 1): [['doc8', [171], 1]],\n",
       "             ('am', 1): [['doc4', [56], 1]],\n",
       "             ('amazingli', 1): [['doc8', [183], 1]],\n",
       "             ('american', 1): [['doc8', [85], 1]],\n",
       "             ('amount', 1): [['doc8', [224], 1]],\n",
       "             ('an', 3): [['doc2', [23, 35, 126, 137], 4],\n",
       "              ['doc8', [2], 1],\n",
       "              ['doc10', [19], 1]],\n",
       "             ('android', 2): [['doc2', [36], 1], ['doc6', [47], 1]],\n",
       "             ('anoth', 1): [['doc8', [123], 1]],\n",
       "             ('appreci', 1): [['doc6', [29], 1]],\n",
       "             ('are', 2): [['doc6', [27], 1], ['doc8', [240], 1]],\n",
       "             ('armor', 1): [['doc2', [94], 1]],\n",
       "             ('as', 4): [['doc4', [75, 77], 2],\n",
       "              ['doc8', [244], 1],\n",
       "              ['doc9', [73], 1],\n",
       "              ['doc10', [18], 1]],\n",
       "             ('ask', 1): [['doc9', [28], 1]],\n",
       "             ('asu', 3): [['doc1', [51, 80], 2],\n",
       "              ['doc3', [31], 1],\n",
       "              ['doc8', [31, 62, 159, 188, 205], 5]],\n",
       "             ('automat', 1): [['doc8', [88], 1]],\n",
       "             ('avoid', 1): [['doc8', [187], 1]],\n",
       "             ('aw', 1): [['doc1', [108], 1]],\n",
       "             ('awesom', 1): [['doc1', [38], 1]],\n",
       "             ('back', 2): [['doc2', [49], 1]],\n",
       "             ('bad', 1): [['doc3', [23, 82], 2]],\n",
       "             ('batteri', 1): [['doc5', [30], 1]],\n",
       "             ('be', 2): [['doc2', [54], 1], ['doc3', [51], 1]],\n",
       "             ('becam', 1): [['doc8', [130], 1]],\n",
       "             ('becaus', 1): [['doc8', [148, 191], 2]],\n",
       "             ('been', 2): [['doc4', [2], 1], ['doc8', [231], 1]],\n",
       "             ('befor', 1): [['doc2', [25], 1]],\n",
       "             ('big', 2): [['doc2', [73], 1], ['doc4', [79], 1]],\n",
       "             ('birthday', 1): [['doc2', [12], 1]],\n",
       "             ('book', 1): [['doc4', [5], 1]],\n",
       "             ('bought', 3): [['doc4', [12], 1],\n",
       "              ['doc5', [3], 1],\n",
       "              ['doc8', [97], 1]],\n",
       "             ('brick', 1): [['doc8', [0], 1]],\n",
       "             ('brows', 1): [['doc4', [40], 1]],\n",
       "             ('but', 6): [['doc1', [28], 1],\n",
       "              ['doc2', [39, 112, 131], 3],\n",
       "              ['doc3', [40, 59], 2],\n",
       "              ['doc4', [87], 1],\n",
       "              ['doc9', [79], 1],\n",
       "              ['doc10', [21], 1]],\n",
       "             ('button', 1): [['doc2', [50], 1]],\n",
       "             ('buy', 1): [['doc8', [107], 1]],\n",
       "             ('by', 2): [['doc8', [1, 59], 2], ['doc9', [91], 1]],\n",
       "             ('camera', 2): [['doc2', [108], 1], ['doc6', [25], 1]],\n",
       "             ('can', 2): [['doc6', [9], 1], ['doc9', [63], 1]],\n",
       "             ('case', 1): [['doc2', [99], 1]],\n",
       "             ('charg', 1): [['doc3', [20, 36, 75], 3]],\n",
       "             ('child', 1): [['doc9', [78, 85], 2]],\n",
       "             ('claim', 1): [['doc8', [104], 1]],\n",
       "             ('common', 1): [['doc8', [124], 1]],\n",
       "             ('compani', 1): [['doc8', [169], 1]],\n",
       "             ('compar', 2): [['doc1', [24, 66], 2], ['doc6', [80], 1]],\n",
       "             ('complet', 1): [['doc8', [163, 190], 2]],\n",
       "             ('confid', 1): [['doc8', [166], 1]],\n",
       "             ('control', 1): [['doc7', [2], 1]],\n",
       "             ('conveni', 1): [['doc4', [89], 1]],\n",
       "             ('convinc', 1): [['doc9', [18], 1]],\n",
       "             ('cooler', 1): [['doc3', [54], 1]],\n",
       "             ('cost', 1): [['doc8', [220], 1]],\n",
       "             ('could', 1): [['doc10', [9], 1]],\n",
       "             ('count', 1): [['doc4', [96], 1]],\n",
       "             ('crappi', 1): [['doc9', [5], 1]],\n",
       "             ('cursor', 1): [['doc2', [59], 1]],\n",
       "             ('custom', 1): [['doc8', [243], 1]],\n",
       "             ('d', 1): [['doc2', [20], 1]],\n",
       "             ('deal', 1): [['doc8', [157], 1]],\n",
       "             ('dedic', 1): [['doc4', [83], 1]],\n",
       "             ('defect', 1): [['doc8', [211], 1]],\n",
       "             ('delet', 1): [['doc7', [6], 1]],\n",
       "             ('deserv', 1): [['doc9', [86], 1]],\n",
       "             ('devic', 3): [['doc2', [117], 1],\n",
       "              ['doc5', [26], 1],\n",
       "              ['doc10', [33], 1]],\n",
       "             ('devicewear', 1): [['doc2', [98], 1]],\n",
       "             ('dice', 1): [['doc8', [199], 1]],\n",
       "             ('differ', 1): [['doc6', [13], 1]],\n",
       "             ('disast', 1): [['doc9', [49], 1]],\n",
       "             ('do', 4): [['doc1', [19], 1],\n",
       "              ['doc7', [9], 1],\n",
       "              ['doc8', [236], 1],\n",
       "              ['doc9', [0], 1]],\n",
       "             ('doe', 2): [['doc1', [56], 1], ['doc10', [6], 1]],\n",
       "             ('drop', 1): [['doc5', [36], 1]],\n",
       "             ('eas', 1): [['doc4', [61], 1]],\n",
       "             ('easili', 1): [['doc6', [10], 1]],\n",
       "             ('ebay', 1): [['doc8', [110], 1]],\n",
       "             ('ebook', 1): [['doc2', [82], 1]],\n",
       "             ('edit', 1): [['doc4', [47, 63, 85], 3]],\n",
       "             ('elect', 1): [['doc7', [25], 1]],\n",
       "             ('emul', 1): [['doc4', [37], 1]],\n",
       "             ('end', 2): [['doc8', [70], 1], ['doc9', [43], 1]],\n",
       "             ('environ', 1): [['doc3', [55], 1]],\n",
       "             ('estim', 1): [['doc8', [80], 1]],\n",
       "             ('etc', 1): [['doc5', [41], 1]],\n",
       "             ('even', 2): [['doc1', [45, 94, 109], 3], ['doc8', [180], 1]],\n",
       "             ('everyth', 1): [['doc10', [7], 1]],\n",
       "             ('expens', 1): [['doc8', [247], 1]],\n",
       "             ('experienc', 1): [['doc8', [58], 1]],\n",
       "             ('express', 1): [['doc8', [86], 1]],\n",
       "             ('fail', 1): [['doc8', [121], 1]],\n",
       "             ('fall', 1): [['doc9', [2], 1]],\n",
       "             ('fast', 2): [['doc2', [153], 1], ['doc6', [34], 1]],\n",
       "             ('feel', 1): [['doc6', [33, 70], 2]],\n",
       "             ('few', 2): [['doc3', [6], 1], ['doc4', [8], 1]],\n",
       "             ('final', 1): [['doc4', [11], 1]],\n",
       "             ('fine', 1): [['doc2', [122], 1]],\n",
       "             ('first', 2): [['doc3', [5], 1], ['doc8', [20, 154], 2]],\n",
       "             ('five', 1): [['doc3', [89], 1]],\n",
       "             ('fix', 2): [['doc3', [39], 1], ['doc8', [36, 210], 2]],\n",
       "             ('flaw', 1): [['doc9', [37], 1]],\n",
       "             ('flawless', 1): [['doc1', [84], 1]],\n",
       "             ('for', 5): [['doc2', [10, 144], 2],\n",
       "              ['doc3', [3, 32], 2],\n",
       "              ['doc4', [6, 20, 32], 3],\n",
       "              ['doc8', [18, 122], 2],\n",
       "              ['doc9', [3, 14], 2]],\n",
       "             ('from', 3): [['doc1', [32, 53, 79, 104], 4],\n",
       "              ['doc4', [66], 1],\n",
       "              ['doc6', [1], 1]],\n",
       "             ('frustrat', 1): [['doc9', [90], 1]],\n",
       "             ('function', 1): [['doc3', [57], 1]],\n",
       "             ('game', 2): [['doc4', [35], 1], ['doc10', [29], 1]],\n",
       "             ('garbag', 1): [['doc9', [62], 1]],\n",
       "             ('gear', 1): [['doc1', [87], 1]],\n",
       "             ('get', 5): [['doc2', [32], 1],\n",
       "              ['doc3', [88], 1],\n",
       "              ['doc4', [103], 1],\n",
       "              ['doc8', [77], 1],\n",
       "              ['doc9', [88], 1]],\n",
       "             ('give', 1): [['doc9', [71], 1]],\n",
       "             ('go', 1): [['doc3', [81], 1]],\n",
       "             ('good', 4): [['doc2', [87], 1],\n",
       "              ['doc4', [76], 1],\n",
       "              ['doc5', [25, 29], 2],\n",
       "              ['doc8', [177], 1]],\n",
       "             ('googl', 3): [['doc1', [54, 55], 2],\n",
       "              ['doc7', [1, 22], 2],\n",
       "              ['doc8', [46], 1]],\n",
       "             ('gopro', 1): [['doc4', [49], 1]],\n",
       "             ('got', 2): [['doc3', [78], 1], ['doc8', [112], 1]],\n",
       "             ('great', 5): [['doc1', [89], 1],\n",
       "              ['doc2', [143], 1],\n",
       "              ['doc3', [2], 1],\n",
       "              ['doc6', [18], 1],\n",
       "              ['doc10', [3], 1]],\n",
       "             ('guess', 1): [['doc6', [52], 1]],\n",
       "             ('ha', 2): [['doc1', [13, 49], 2], ['doc5', [15], 1]],\n",
       "             ('had', 4): [['doc3', [26], 1],\n",
       "              ['doc4', [18], 1],\n",
       "              ['doc8', [206], 1],\n",
       "              ['doc9', [56], 1]],\n",
       "             ('happen', 1): [['doc8', [24], 1]],\n",
       "             ('happi', 2): [['doc4', [101], 1], ['doc6', [89], 1]],\n",
       "             ('hard', 1): [['doc9', [11, 13], 2]],\n",
       "             ('hardwar', 2): [['doc1', [78], 1], ['doc9', [95], 1]],\n",
       "             ('hate', 1): [['doc9', [45], 1]],\n",
       "             ('have', 5): [['doc2', [47, 125], 2],\n",
       "              ['doc3', [11], 1],\n",
       "              ['doc6', [68], 1],\n",
       "              ['doc8', [176, 219, 230], 3],\n",
       "              ['doc10', [26], 1]],\n",
       "             ('he', 1): [['doc5', [34], 1]],\n",
       "             ('hero4', 1): [['doc4', [68, 108], 2]],\n",
       "             ('hi', 1): [['doc5', [6], 1]],\n",
       "             ('hold', 1): [['doc7', [20], 1]],\n",
       "             ('hundr', 1): [['doc8', [60], 1]],\n",
       "             ('husband', 1): [['doc2', [7], 1]],\n",
       "             ('if', 4): [['doc1', [46, 110], 2],\n",
       "              ['doc2', [113], 1],\n",
       "              ['doc3', [91], 1]],\n",
       "             ('immedi', 1): [['doc2', [90], 1]],\n",
       "             ('in', 3): [['doc8', [74, 161], 2]],\n",
       "             ('instead', 3): [['doc5', [9], 1],\n",
       "              ['doc8', [238], 1],\n",
       "              ['doc9', [64], 1]],\n",
       "             ('internet', 1): [['doc10', [27], 1]],\n",
       "             ('ipad', 1): [['doc2', [138], 1]],\n",
       "             ('iphon', 1): [['doc2', [24, 127], 2]],\n",
       "             ('ipod', 1): [['doc2', [129], 1]],\n",
       "             ('issu', 2): [['doc3', [12, 44], 2], ['doc8', [57, 67, 125], 3]],\n",
       "             ('it', 8): [['doc2', [43, 63, 84, 101, 104, 119], 6],\n",
       "              ['doc3', [29, 56, 61, 92], 4],\n",
       "              ['doc4', [19, 31, 52, 72], 4],\n",
       "              ['doc5', [17, 37], 2],\n",
       "              ['doc6', [32], 1],\n",
       "              ['doc8', [17, 37, 53, 73, 98, 113, 120, 152, 217], 9],\n",
       "              ['doc9', [36, 67, 72, 92], 4],\n",
       "              ['doc10', [11, 16, 22], 3]],\n",
       "             ('jumpi', 1): [['doc8', [131], 1]],\n",
       "             ('junk', 1): [['doc8', [137], 1]],\n",
       "             ('just', 2): [['doc4', [45, 100], 2], ['doc8', [75], 1]],\n",
       "             ('justifi', 1): [['doc9', [35], 1]],\n",
       "             ('kinemast', 1): [['doc4', [54], 1]],\n",
       "             ('know', 2): [['doc1', [48], 1], ['doc4', [71], 1]],\n",
       "             ('laptop', 1): [['doc5', [12], 1]],\n",
       "             ('later', 1): [['doc8', [119], 1]],\n",
       "             ('least', 1): [['doc7', [16], 1]],\n",
       "             ('less', 1): [['doc8', [246], 1]],\n",
       "             ('life', 1): [['doc5', [31], 1]],\n",
       "             ('lighter', 1): [['doc6', [78], 1]],\n",
       "             ('like', 3): [['doc1', [16], 1],\n",
       "              ['doc2', [66], 1],\n",
       "              ['doc8', [151], 1]],\n",
       "             ('littl', 1): [['doc4', [92], 1]],\n",
       "             ('loss', 1): [['doc8', [164, 248], 2]],\n",
       "             ('lot', 2): [['doc2', [80], 1], ['doc5', [20], 1]],\n",
       "             ('love', 2): [['doc2', [2, 46, 53], 3], ['doc8', [16], 1]],\n",
       "             ('lower', 1): [['doc1', [29], 1]],\n",
       "             ('m', 4): [['doc4', [99], 1],\n",
       "              ['doc6', [57, 87], 2],\n",
       "              ['doc8', [193], 1],\n",
       "              ['doc9', [22, 27], 2]],\n",
       "             ('machin', 1): [['doc4', [86], 1]],\n",
       "             ('mainli', 1): [['doc10', [17], 1]],\n",
       "             ('me', 1): [['doc2', [9], 1]],\n",
       "             ('model', 1): [['doc6', [6], 1]],\n",
       "             ('modern', 1): [['doc1', [27], 1]],\n",
       "             ('money', 2): [['doc5', [8], 1], ['doc8', [105, 226], 2]],\n",
       "             ('month', 2): [['doc3', [7], 1], ['doc8', [26, 118], 2]],\n",
       "             ('more', 2): [['doc1', [26], 1], ['doc8', [39], 1]],\n",
       "             ('most', 1): [['doc1', [6], 1]],\n",
       "             ('move', 1): [['doc2', [57], 1]],\n",
       "             ('movi', 1): [['doc4', [34], 1]],\n",
       "             ('much', 3): [['doc2', [133], 1],\n",
       "              ['doc8', [142], 1],\n",
       "              ['doc9', [30, 51], 2]],\n",
       "             ('my', 5): [['doc2', [3, 11, 107], 3],\n",
       "              ['doc4', [48, 67, 78, 104, 107], 5],\n",
       "              ['doc6', [38, 72, 91], 3]],\n",
       "             ('myself', 1): [['doc9', [19], 1]],\n",
       "             ('net', 1): [['doc4', [4], 1]],\n",
       "             ('new', 1): [['doc8', [42], 1]],\n",
       "             ('next', 1): [['doc1', [98], 1]],\n",
       "             ('nexu', 3): [['doc1', [52], 1],\n",
       "              ['doc2', [4], 1],\n",
       "              ['doc6', [3, 40], 2]],\n",
       "             ('nice', 1): [['doc10', [24], 1]],\n",
       "             ('no', 1): [['doc9', [84], 1]],\n",
       "             ('not', 7): [['doc2', [71], 1],\n",
       "              ['doc3', [46], 1],\n",
       "              ['doc4', [74], 1],\n",
       "              ['doc6', [58], 1],\n",
       "              ['doc7', [10], 1],\n",
       "              ['doc8', [194], 1],\n",
       "              ['doc9', [1], 1]],\n",
       "             ('notic', 1): [['doc6', [11], 1]],\n",
       "             ('now', 4): [['doc2', [40], 1],\n",
       "              ['doc4', [10, 23, 25], 3],\n",
       "              ['doc8', [186], 1]],\n",
       "             ('off', 2): [['doc4', [106], 1], ['doc8', [242], 1]],\n",
       "             ('older', 1): [['doc6', [5, 39, 73], 3]],\n",
       "             ('one', 3): [['doc1', [1, 3, 69], 3],\n",
       "              ['doc6', [83], 1],\n",
       "              ['doc8', [43, 117, 182], 3]],\n",
       "             ('onli', 3): [['doc1', [40], 1],\n",
       "              ['doc2', [21], 1],\n",
       "              ['doc6', [54], 1]],\n",
       "             ('onto', 1): [['doc4', [110], 1]],\n",
       "             ('oper', 1): [['doc2', [37], 1]],\n",
       "             ('option', 1): [['doc1', [31], 1]],\n",
       "             ('or', 4): [['doc1', [72], 1],\n",
       "              ['doc2', [74], 1],\n",
       "              ['doc4', [81], 1],\n",
       "              ['doc7', [14], 1]],\n",
       "             ('out', 1): [['doc8', [27], 1]],\n",
       "             ('over', 2): [['doc4', [21], 1], ['doc8', [5], 1]],\n",
       "             ('overal', 1): [['doc6', [31, 85], 2]],\n",
       "             ('own', 1): [['doc1', [62], 1]],\n",
       "             ('part', 1): [['doc8', [108], 1]],\n",
       "             ('picki', 1): [['doc9', [24], 1]],\n",
       "             ('piec', 2): [['doc8', [135], 1], ['doc9', [47], 1]],\n",
       "             ('plu', 1): [['doc1', [21], 1]],\n",
       "             ('point', 1): [['doc9', [54], 1]],\n",
       "             ('port', 1): [['doc3', [21, 76], 2]],\n",
       "             ('power', 1): [['doc1', [7], 1]],\n",
       "             ('prefer', 1): [['doc2', [42, 134], 2]],\n",
       "             ('present', 1): [['doc9', [75], 1]],\n",
       "             ('price', 2): [['doc1', [90], 1], ['doc2', [141], 1]],\n",
       "             ('problem', 3): [['doc3', [37], 1],\n",
       "              ['doc4', [26], 1],\n",
       "              ['doc8', [48, 209], 2]],\n",
       "             ('product', 1): [['doc8', [175, 189], 2]],\n",
       "             ('profil', 1): [['doc1', [30], 1]],\n",
       "             ('properli', 1): [['doc3', [58, 95], 2]],\n",
       "             ('protect', 1): [['doc2', [103], 1]],\n",
       "             ('protector', 1): [['doc2', [96], 1]],\n",
       "             ('purchas', 1): [['doc6', [92], 1]],\n",
       "             ('push', 1): [['doc8', [4], 1]],\n",
       "             ('put', 2): [['doc2', [91], 1], ['doc7', [17], 1]],\n",
       "             ('quit', 2): [['doc5', [18], 1], ['doc6', [88], 1]],\n",
       "             ('react', 1): [['doc6', [75], 1]],\n",
       "             ('read', 2): [['doc2', [78], 1]],\n",
       "             ('realiz', 1): [['doc9', [82], 1]],\n",
       "             ('realli', 3): [['doc2', [1], 1],\n",
       "              ['doc6', [28], 1],\n",
       "              ['doc8', [150], 1]],\n",
       "             ('rear', 1): [['doc6', [24], 1]],\n",
       "             ('recommend', 1): [['doc5', [44], 1]],\n",
       "             ('releas', 1): [['doc8', [214], 1]],\n",
       "             ('repair', 2): [['doc3', [33], 1], ['doc8', [79], 1]],\n",
       "             ('replac', 1): [['doc3', [79], 1]],\n",
       "             ('respons', 2): [['doc5', [28], 1], ['doc6', [36, 63], 2]],\n",
       "             ('restart', 1): [['doc2', [115], 1]],\n",
       "             ('result', 1): [['doc8', [160], 1]],\n",
       "             ('return', 1): [['doc9', [66], 1]],\n",
       "             ('review', 1): [['doc8', [178], 1]],\n",
       "             ('revis', 1): [['doc8', [216], 1]],\n",
       "             ('ridicul', 1): [['doc1', [44], 1]],\n",
       "             ('right', 1): [['doc8', [233], 1]],\n",
       "             ('rock', 1): [['doc1', [93], 1]],\n",
       "             ('roll', 1): [['doc8', [197], 1]],\n",
       "             ('s', 4): [['doc3', [62], 1],\n",
       "              ['doc4', [13, 73], 2],\n",
       "              ['doc5', [35], 1],\n",
       "              ['doc10', [23], 1]],\n",
       "             ('same', 1): [['doc10', [32], 1]],\n",
       "             ('save', 1): [['doc5', [7], 1]],\n",
       "             ('screen', 5): [['doc1', [36], 1],\n",
       "              ['doc2', [95], 1],\n",
       "              ['doc3', [16, 43, 66], 3],\n",
       "              ['doc6', [16, 66], 2],\n",
       "              ['doc8', [129], 1]],\n",
       "             ('see', 1): [['doc8', [52], 1]],\n",
       "             ('seem', 1): [['doc3', [49], 1]],\n",
       "             ('send', 2): [['doc3', [28], 1], ['doc8', [72], 1]],\n",
       "             ('sever', 1): [['doc5', [38], 1]],\n",
       "             ('shame', 1): [['doc8', [147], 1]],\n",
       "             ('shop', 1): [['doc4', [39], 1]],\n",
       "             ('should', 1): [['doc7', [23], 1]],\n",
       "             ('size', 1): [['doc2', [68], 1]],\n",
       "             ('slimport', 1): [['doc1', [17], 1]],\n",
       "             ('slow', 1): [['doc9', [7], 1]],\n",
       "             ('sluggi', 1): [['doc9', [93], 1]],\n",
       "             ('small', 1): [['doc2', [75], 1]],\n",
       "             ('so', 3): [['doc2', [26], 1], ['doc9', [50, 89], 2]],\n",
       "             ('softwar', 1): [['doc1', [102], 1]],\n",
       "             ('some', 2): [['doc1', [14], 1], ['doc8', [172], 1]],\n",
       "             ('sometim', 1): [['doc2', [106], 1]],\n",
       "             ('son', 1): [['doc5', [2], 1]],\n",
       "             ('soni', 1): [['doc1', [73], 1]],\n",
       "             ('soon', 1): [['doc9', [80], 1]],\n",
       "             ('speaker', 1): [['doc6', [21], 1]],\n",
       "             ('special', 1): [['doc6', [43], 1]],\n",
       "             ('star', 2): [['doc1', [83, 107], 2], ['doc3', [90], 1]],\n",
       "             ('start', 2): [['doc3', [10], 1], ['doc4', [46], 1]],\n",
       "             ('stero', 1): [['doc6', [20], 1]],\n",
       "             ('still', 1): [['doc1', [12, 92], 2]],\n",
       "             ('stock', 1): [['doc8', [13], 1]],\n",
       "             ('storag', 1): [['doc2', [147], 1]],\n",
       "             ('submit', 1): [['doc8', [82], 1]],\n",
       "             ('super', 1): [['doc9', [6], 1]],\n",
       "             ('sure', 1): [['doc2', [30], 1]],\n",
       "             ('surpris', 2): [['doc2', [8], 1], ['doc4', [58], 1]],\n",
       "             ('suspens', 1): [['doc7', [26], 1]],\n",
       "             ('system', 2): [['doc1', [8, 74], 2], ['doc2', [38], 1]],\n",
       "             ('tablet', 6): [['doc2', [150], 1],\n",
       "              ['doc3', [86], 1],\n",
       "              ['doc4', [14, 93], 2],\n",
       "              ['doc6', [74], 1],\n",
       "              ['doc9', [8], 1],\n",
       "              ['doc10', [4], 1]],\n",
       "             ('tech', 1): [['doc2', [93], 1]],\n",
       "             ('temperatur', 1): [['doc3', [52], 1]],\n",
       "             ('than', 2): [['doc2', [118], 1], ['doc8', [40], 1]],\n",
       "             ('that', 6): [['doc1', [18, 43], 2],\n",
       "              ['doc2', [151], 1],\n",
       "              ['doc3', [77], 1],\n",
       "              ['doc6', [71], 1],\n",
       "              ['doc8', [83], 1],\n",
       "              ['doc9', [20, 25, 46, 83], 4]],\n",
       "             ('their', 2): [['doc1', [61], 1], ['doc8', [174], 1]],\n",
       "             ('them', 2): [['doc7', [18], 1], ['doc8', [201, 221], 2]],\n",
       "             ('then', 2): [['doc3', [9, 18], 2], ['doc8', [22, 101], 2]],\n",
       "             ('they', 1): [['doc8', [239], 1]],\n",
       "             ('thi', 9): [['doc1', [0, 91], 2],\n",
       "              ['doc2', [17, 70, 135], 3],\n",
       "              ['doc3', [85], 1],\n",
       "              ['doc4', [91], 1],\n",
       "              ['doc5', [4], 1],\n",
       "              ['doc6', [82], 1],\n",
       "              ['doc8', [9, 23, 181], 3],\n",
       "              ['doc9', [4], 1],\n",
       "              ['doc10', [0], 1]],\n",
       "             ('thing', 4): [['doc1', [15], 1],\n",
       "              ['doc6', [55], 1],\n",
       "              ['doc7', [7], 1],\n",
       "              ['doc8', [234], 1]],\n",
       "             ('thought', 1): [['doc9', [69], 1]],\n",
       "             ('thrill', 1): [['doc6', [59], 1]],\n",
       "             ('throw', 1): [['doc9', [58], 1]],\n",
       "             ('time', 2): [['doc5', [39], 1], ['doc8', [143], 1]],\n",
       "             ('to', 9): [['doc1', [25], 1],\n",
       "              ['doc2', [34, 56, 102, 136], 4],\n",
       "              ['doc3', [27, 30, 50], 3],\n",
       "              ['doc4', [102], 1],\n",
       "              ['doc6', [46, 76, 81], 3],\n",
       "              ['doc7', [5, 12], 2],\n",
       "              ['doc8', [35, 76, 84, 92, 106, 196, 235], 7],\n",
       "              ['doc9', [17, 34, 52, 70, 76, 87], 6],\n",
       "              ['doc10', [12, 25], 2]],\n",
       "             ('too', 5): [['doc1', [100], 1],\n",
       "              ['doc2', [72], 1],\n",
       "              ['doc7', [0], 1],\n",
       "              ['doc8', [141], 1],\n",
       "              ['doc9', [23, 29], 2]],\n",
       "             ('topnotch', 1): [['doc1', [86], 1]],\n",
       "             ('touch', 4): [['doc2', [130], 1],\n",
       "              ['doc3', [15, 42, 65], 3],\n",
       "              ['doc6', [79], 1],\n",
       "              ['doc8', [128], 1]],\n",
       "             ('tough', 1): [['doc5', [32], 1]],\n",
       "             ('tri', 1): [['doc9', [10, 33], 2]],\n",
       "             ('trivial', 1): [['doc8', [223], 1]],\n",
       "             ('two', 1): [['doc9', [15], 1]],\n",
       "             ('ugli', 1): [['doc9', [96], 1]],\n",
       "             ('unabl', 1): [['doc7', [4], 1]],\n",
       "             ('unit', 1): [['doc8', [212], 1]],\n",
       "             ('unlik', 1): [['doc6', [37], 1]],\n",
       "             ('unrespons', 1): [['doc8', [133], 1]],\n",
       "             ('up', 2): [['doc8', [71], 1], ['doc9', [44], 1]],\n",
       "             ('updat', 2): [['doc1', [112], 1], ['doc8', [3], 1]],\n",
       "             ('upgrad', 1): [['doc6', [0, 45], 2]],\n",
       "             ('use', 7): [['doc1', [59], 1],\n",
       "              ['doc2', [22, 33], 2],\n",
       "              ['doc4', [3, 30], 2],\n",
       "              ['doc5', [16], 1],\n",
       "              ['doc7', [13], 1],\n",
       "              ['doc8', [102], 1],\n",
       "              ['doc10', [15], 1]],\n",
       "             ('ve', 2): [['doc4', [1, 17], 2], ['doc8', [139], 1]],\n",
       "             ('vein', 1): [['doc9', [40], 1]],\n",
       "             ('veri', 2): [['doc4', [57], 1], ['doc9', [12], 1]],\n",
       "             ('video', 1): [['doc4', [50, 65, 84, 105], 4]],\n",
       "             ('vimeo', 1): [['doc4', [111], 1]],\n",
       "             ('wa', 4): [['doc1', [2], 1],\n",
       "              ['doc2', [28, 142], 2],\n",
       "              ['doc3', [38], 1],\n",
       "              ['doc8', [10], 1]],\n",
       "             ('want', 4): [['doc2', [62], 1],\n",
       "              ['doc7', [11], 1],\n",
       "              ['doc8', [32], 1],\n",
       "              ['doc10', [10], 1]],\n",
       "             ('warmer', 1): [['doc3', [63], 1]],\n",
       "             ('warranti', 1): [['doc8', [29, 94], 2]],\n",
       "             ('wast', 1): [['doc8', [140], 1]],\n",
       "             ('watch', 1): [['doc4', [33], 1]],\n",
       "             ('we', 1): [['doc1', [65], 1]],\n",
       "             ('web', 1): [['doc4', [42], 1]],\n",
       "             ('week', 1): [['doc9', [16], 1]],\n",
       "             ('weight', 1): [['doc2', [85], 1]],\n",
       "             ('well', 1): [['doc2', [156], 1]],\n",
       "             ('went', 1): [['doc3', [22], 1]],\n",
       "             ('were', 1): [['doc3', [45], 1]],\n",
       "             ('what', 1): [['doc4', [95], 1]],\n",
       "             ('whatsoev', 1): [['doc4', [27], 1]],\n",
       "             ('when', 3): [['doc1', [22, 64], 2],\n",
       "              ['doc3', [60], 1],\n",
       "              ['doc8', [95], 1]],\n",
       "             ('where', 1): [['doc2', [60], 1]],\n",
       "             ('which', 1): [['doc8', [87], 1]],\n",
       "             ('widespread', 1): [['doc8', [56], 1]],\n",
       "             ('will', 1): [['doc8', [51, 195], 2]],\n",
       "             ('with', 7): [['doc1', [67], 1],\n",
       "              ['doc2', [16], 1],\n",
       "              ['doc3', [13], 1],\n",
       "              ['doc4', [53], 1],\n",
       "              ['doc5', [5], 1],\n",
       "              ['doc6', [90], 1],\n",
       "              ['doc8', [158, 167, 200], 3]],\n",
       "             ('work', 3): [['doc2', [111, 120, 155], 3],\n",
       "              ['doc3', [1, 69, 94], 3],\n",
       "              ['doc8', [114], 1]],\n",
       "             ('worst', 1): [['doc1', [58], 1]],\n",
       "             ('would', 3): [['doc3', [87], 1],\n",
       "              ['doc5', [43], 1],\n",
       "              ['doc8', [218, 229], 2]],\n",
       "             ('write', 1): [['doc8', [241], 1]],\n",
       "             ('year', 4): [['doc1', [99], 1],\n",
       "              ['doc2', [14], 1],\n",
       "              ['doc4', [9], 1],\n",
       "              ['doc8', [21, 91], 2]],\n",
       "             ('you', 3): [['doc6', [8], 1],\n",
       "              ['doc7', [8], 1],\n",
       "              ['doc8', [50], 1]]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_inverted_index_df = defaultdict(list)\n",
    "positional_inverted_index = defaultdict(list)\n",
    "\n",
    "for k, v in inverted_index.items():\n",
    "    \n",
    "    for i in v:\n",
    "        position = []\n",
    "        term_freq = 0\n",
    "        doc_arr = nltk.tokenize.word_tokenize(dd[i])\n",
    "        for j in range(len(doc_arr)):\n",
    "            doc_word = re.sub(\"[^a-zA-Z0-9]+\", \"\", doc_arr[j])\n",
    "            if doc_word == k :\n",
    "                position.append(j)\n",
    "                term_freq += 1\n",
    "        if term_freq>0:\n",
    "            positional_inverted_index_df[(k,len(v))].append([i,position,term_freq]) #Positional Inverted index with term, document frequency as the key and the positions, term frequency, doc id as the value/posting list\n",
    "            positional_inverted_index[k].append([i,position,term_freq])#Positional Inverted index with term as the key and the positions, term frequency, doc id as the value/posting list\n",
    "            \n",
    "                \n",
    "positional_inverted_index_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#writing the inverted index to a file\n",
    "csv_columns = ['Index,Document Frequency','Posting List']\n",
    "with open('Positional_inverted_index.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(csv_columns)\n",
    "    for k,v in positional_inverted_index_df.items():\n",
    "        writer.writerow([k,str(v).strip('[]')])\n",
    "        #print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2 Processing the proximity query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code processes the proximity queries and retrieves all the documents that match the proximity criterion.\n",
    "\n",
    "Note: It assumes that a proximity operator will always contain two terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximity_query(query,n):\n",
    "    query = stemming_and_stopwords_removal(query)\n",
    "    p1_index = positional_inverted_index[query[0]] #posting list for the first query term\n",
    "    p2_index = positional_inverted_index[query[1]] #posting list for the second query term\n",
    "    i = 0\n",
    "    j = 0\n",
    "    positions1 = []  #array to hold the positions of first query\n",
    "    positions2 = []  #array to hold the positions of second query\n",
    "    for i in range(len(p1_index)):\n",
    "        for j in range(len(p1_index[i][1])):\n",
    "            positions1.append(p1_index[i][1][j]) #Appending the positions to the array\n",
    "\n",
    "    for i in range(len(p2_index)):\n",
    "        for j in range(len(p2_index[i][1])):\n",
    "            positions2.append(p2_index[i][1][j])\n",
    "    count = 0\n",
    "    indices1 = []  \n",
    "    indices2 = []\n",
    "    for i in positions1:\n",
    "        for j in positions2:\n",
    "            if j>i and abs(i-j) <= n+1: #If the difference between the positions == n, then those positions are added to the indices array\n",
    "                indices1.append(i)     #n+1, because I have considered indices as the position\n",
    "                indices2.append(j)\n",
    "\n",
    "    doc1 = set()\n",
    "    for i in range(len(p1_index)):\n",
    "        for j in range(len(p1_index[i][1])):\n",
    "            for k in indices1:\n",
    "                if p1_index[i][1][j] == k:  #Find the document where the position1 is equal to the position == n\n",
    "                    doc1.add(p1_index[i][0])\n",
    "    doc2 = set()\n",
    "    for i in range(len(p2_index)):\n",
    "        for j in range(len(p2_index[i][1])):\n",
    "            for k in indices2:\n",
    "                if p2_index[i][1][j] == k:  #Find the document where the position2 is equal to the position == n\n",
    "                    doc2.add(p2_index[i][0])\n",
    "    \n",
    "\n",
    "    return doc1.intersection(doc2)  #Both the terms should be present in the same document. Therefore finding the common documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3 Processing the proximity and free text queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code retrieves the document matching the proximity operator and then it ranks the documents using TF IDF. In case of a combination of proximity query and free text query, it first filters the set of documents matching the proximity query and then it ranks those filtered document to obtain the final scoring list. \n",
    "\n",
    "Note: The following code assumes there can be maximum of two proximity operators in a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import operator\n",
    "N = 10\n",
    "\n",
    "def check_proximity(query):\n",
    "    if \"(\" in query:  #If a parantheses is present, then it is a proximity operator\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def process_query(query):\n",
    "    if check_proximity(query):\n",
    "        \n",
    "        nums = re.findall(\"\\d\",query) #Retrieving the value of n from the proximity operator\n",
    "        if len(nums)>1: #If there are two n values\n",
    "            n1 = nums[0] \n",
    "            n2 = nums[1]\n",
    "            clean_query = stemming_and_stopwords_removal(str(query)) # Clean the query to get the result as bag of words\n",
    "            res1 = proximity_query(str(clean_query[1:3]),int(n1)) #Find the documents that match the proximity criterion\n",
    "            res_2 = proximity_query(str(clean_query[4:6]),int(n2))\n",
    "            doc_res = res1.union(res_2) #Take all the subset of documents filtered after the proximity criterion is satisfied\n",
    "        else:\n",
    "            n1 = nums[0] #If there is only one proximity operator\n",
    "            clean_query = stemming_and_stopwords_removal(str(query))\n",
    "            res1 = proximity_query(str(clean_query[1:3]),int(n1))\n",
    "            doc_res = res1\n",
    "        return calculate_score(doc_res, clean_query)\n",
    "   \n",
    "    return free_text_query(query) #If there are no proximity operators in the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4 Calculating scores for proximity queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(doc_res,clean_query):\n",
    "    h_map = defaultdict(list)\n",
    "    for i in nltk.tokenize.word_tokenize(re.sub(\"[^a-zA-Z]+\", \" \", str(clean_query))):\n",
    "        df = len(positional_inverted_index[i])\n",
    "        p_index = positional_inverted_index[i]\n",
    "        #print(i,\"df\",df)\n",
    "        for j in range(len(p_index)):  #Retrieves the Term Frequency and document frequency of the query terms from the positional inverted index\n",
    "            if p_index[j][0] in doc_res and [i,p_index[j][2],df] not in  h_map[p_index[j][0]] :\n",
    "                h_map[p_index[j][0]].append([i,p_index[j][2],df]) #Storing it in a Dictionary\n",
    "\n",
    "\n",
    "    return calculate_tfIdf(h_map) #Function for calculating the scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4 Calculating scores for free text queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_text_query(query):\n",
    "    h_map = defaultdict(list)\n",
    "    query = stemming_and_stopwords_removal(query)\n",
    "    N = 10\n",
    "    for i in query:\n",
    "        p_index = positional_inverted_index[i]\n",
    "        df = len(p_index)\n",
    "        for j in range(len(p_index)):\n",
    "            tf = p_index[j][2]\n",
    "            if ([i,tf,df] not in h_map[p_index[j][0]]): #Retrieves the Term Frequency and document frequency of the query terms from the positional inverted index\n",
    "                h_map[p_index[j][0]].append([i,tf,df]) #Storing it in a Dictionary\n",
    "            #print(i,\"tf=\",tf,\"df=\",df,p_index[j][0])\n",
    "    return calculate_tfIdf(h_map) #Function for calculating the scores\n",
    "    #return h_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfIdf(h_map):\n",
    "    scores = {}\n",
    "    N = 10\n",
    "    for k, v in h_map.items():\n",
    "        tf_idf = 0\n",
    "        s = 0\n",
    "        for i in range(len(v)):\n",
    "            tf = v[i][1]\n",
    "            #print(v[i][0],tf)\n",
    "            if tf > 0:\n",
    "                \n",
    "                wt = 1 + math.log(v[i][1],2) #Calculating the weight of all terms with non zero TF\n",
    "                #print(v[i][0],wt)\n",
    "            else: \n",
    "                wt = 0\n",
    "            \n",
    "    \n",
    "            df = v[i][2]\n",
    "            idf = math.log((N/df),2) #Calculating the IDF \n",
    "            tf_idf += wt * idf  #TF IDF score of the documents\n",
    "        scores[k] = tf_idf\n",
    "        #print(k,v)\n",
    "    return sorted(scores.items(),key=operator.itemgetter(1),reverse=True) #Rank the documents in decreasing order of their scores.\n",
    "                                                                            #Document with the highest score will appear at the top\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_results_to_file(query,query_results): #Function for writing query results to a file\n",
    "    print(\"Writing to file...\")\n",
    "    with open('Ranked_document_results.csv','a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in query_results:\n",
    "            writer.writerow([query,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc2', 9.476028242987159),\n",
       " ('doc6', 5.795859283219775),\n",
       " ('doc8', 4.058893689053568),\n",
       " ('doc1', 3.4739311883324127),\n",
       " ('doc4', 2.321928094887362)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"nexus like love happy\"\n",
    "write_query_results_to_file(query,process_query(query))\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc8', 8.092002902000804),\n",
       " ('doc3', 4.058893689053568),\n",
       " ('doc1', 3.4739311883324127)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"asus repair\"\n",
    "write_query_results_to_file(query,process_query(query))\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc3', 10.645953244429469), ('doc8', 9.287712379549449)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"0(touch screen) fix repair\"\n",
    "write_query_results_to_file(query,process_query(query))\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc2', 4.058893689053568), ('doc10', 1.736965594166206)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"1(great tablet) 2(tablet fast)\"\n",
    "write_query_results_to_file(query,process_query(query))\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc4', 1.4739311883324124),\n",
       " ('doc2', 0.7369655941662062),\n",
       " ('doc3', 0.7369655941662062),\n",
       " ('doc6', 0.7369655941662062),\n",
       " ('doc9', 0.7369655941662062),\n",
       " ('doc10', 0.7369655941662062)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"tablet\"\n",
    "write_query_results_to_file(query,process_query(query))\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
